{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: univariate stimulus, biophysical dynamics\n",
    "\n",
    "Here we simulate data using the biophysical dynamical cascade model, and then try to estimate parameters with the GLM. The GLM does not have a membrane, so the estimated RF should be the convolution of the input kernel ($k1$) with the membrane kernel ($k2$) which is approximately an exponential decay with time constant $\\tau_m$. However, for biophysical models with a low-threshold potassium current ($K_{LT}$), the kernel gets shifted to shorter lags for the phasic model, which is consistent with a variety of published studies showing that $K_{LT}$ acts as a bandpass filter.\n",
    "\n",
    "This notebook also introduces the use of a raised cosine basis set to reduce the number of parameters in the kernel estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import imp\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sps\n",
    "import quickspikes as qs\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import io, strf, mle, simulate, data, filters, models, spikes, performance\n",
    "import spyks.core as spkc\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    len: 60\n",
    "    ncos: 8\n",
    "data:\n",
    "  source: \"randn\"\n",
    "  stimulus:    \n",
    "    duration: 100000\n",
    "    intro: 100\n",
    "    random_seed: 1\n",
    "  filter:\n",
    "    fn: \"gammadiff\"\n",
    "    tau1: 32.0\n",
    "    tau2: 16.0\n",
    "    amplitude: 10.0\n",
    "    ntau: 60\n",
    "    dt: 10.0\n",
    "  model: \"multivariate_dynamical\"\n",
    "  dynamics:\n",
    "    model: \"../../models/phasic.yml\"\n",
    "    current_scaling: 8.0\n",
    "    current_compression:\n",
    "      intercept: -1.32215976\n",
    "      slope: 0.04068182\n",
    "      V_lower: -100\n",
    "      V_upper: 20\n",
    "    current_recenter: 0.0    \n",
    "  trial_noise:\n",
    "    random_seed: 100\n",
    "    snr: 2.0\n",
    "  dt: 10.0\n",
    "  trials: 10\n",
    "spike_detect:\n",
    "  thresh: -20.0\n",
    "  rise_dt: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, k1t = filters.gammadiff(**cf.data.filter)\n",
    "plt.plot(k1t, k1.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the stimulus and response\n",
    "\n",
    "We are also using gaussian white noise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(io)\n",
    "assim_data = data.randn(cf)\n",
    "assim_data = io.merge_data(simulate.multivariate_dynamical(cf, assim_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(9, 4))\n",
    "t_stim = np.arange(0, cf.data.stimulus.duration, cf.data.dt)\n",
    "t_voltage = np.linspace(0, cf.data.stimulus.duration, assim_data[\"V\"].size)\n",
    "\n",
    "axes[0].plot(t_stim, assim_data[\"stim\"].T)\n",
    "axes[1].plot(t_stim, assim_data[\"I\"], t_voltage, assim_data[\"V\"])\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(0, 8000);\n",
    "print(\"spike count: {}\".format(assim_data[\"spike_v\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "The theano code for setting up maximum likelihood estimation has been factored out into the `mle` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using regularized ML\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "try:\n",
    "    mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                    assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                    assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "# constrain to allowed region\n",
    "#nparams = 1 + mlest.n_hparams + mlest.n_kparams\n",
    "#constraint = models.matconstraint(nparams, cf.model.ataus[0], cf.model.ataus[1], cf.model.t_refract)\n",
    "%time w0 = mlest.estimate(reg_alpha=1.0) #, method='trust-constr', constraints=[constraint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "rf_ml = strf.from_basis(w0[3:], kcosbas)[::-1]\n",
    "plt.plot(k1[0, ::-1], label=\"kernel\")\n",
    "\n",
    "# there is an expected shift due to the filtering properties of the membrane\n",
    "stim_dt = cf.data.dt\n",
    "model_dt = cf.model.dt\n",
    "km, kmt = filters.exponential(46, 1.0, cf.data.filter.ntau * stim_dt, stim_dt)\n",
    "kconv = np.convolve(km[::-1], k1[0, ::-1], mode=\"full\")[:km.size]\n",
    "kconv *= k1.max() / kconv.max()\n",
    "plt.plot(kconv, label=\"expected\")\n",
    "\n",
    "plt.plot(rf_ml * k1.max() / rf_ml.max(), label=\"MLE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stim = data.randn(cf, random_seed=1000)\n",
    "test_data = io.merge_data(simulate.multivariate_dynamical(cf, test_stim, random_seed=1000, trials=10))\n",
    "mltest = mle.mat(test_data[\"stim\"], kcosbas, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                 test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True)\n",
    "axes[0].plot(t_stim, test_data[\"stim\"].T)\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "\n",
    "Vpred = mltest.V(w0)\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[1].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[1].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "upsample = int(cf.data.dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "axes[2].plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "\n",
    "axes[0].set_xlim(0, 4500);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % np.corrcoef(test_psth, pred_psth)[0, 1])\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
