{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: multivariate noise stimulus\n",
    "\n",
    "This is a demo notebook for the GLM estimation algorithm. We simulate data using the GLM, and then try to estimate parameters with the GLM. This notebook demos the use of a multivariate stimulus like a spectrogram, although the stimulus used here is more like 1D visual white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import io, strf, mle, simulate, stimulus, filters, models, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up parameters using YAML and Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            require(\n",
       "                [\n",
       "                    \"notebook/js/codecell\",\n",
       "                    \"codemirror/mode/yaml/yaml\"\n",
       "                ],\n",
       "                function(cc){\n",
       "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
       "                        reg: [\"^%%yaml\"]\n",
       "                    }\n",
       "                }\n",
       "            );\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 30\n",
    "    ncos: 8\n",
    "data:\n",
    "  stimulus:\n",
    "    duration: 400000\n",
    "  model: \"multivariate_glm\"\n",
    "  filter:\n",
    "    fn: \"gabor\"\n",
    "    nfreq: 14\n",
    "    ntau: 30\n",
    "    f_max: 8000\n",
    "    f_peak: 4000\n",
    "    t_peak: 12\n",
    "    ampl: -1\n",
    "    t_sigma: 6\n",
    "    f_sigma: 2400\n",
    "    theta: 0\n",
    "    lmbda: 19\n",
    "    psi: 1.5\n",
    "  adaptation: [7.0, 100.0, 2.0]\n",
    "  trial_noise:\n",
    "    sd: 2.0\n",
    "  random_seed: 1\n",
    "  dt: 10.0\n",
    "  trials: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, _, _ = filters.gabor(**cf.data.filter)\n",
    "plt.imshow(k1, cmap='jet', aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code has been factored out to the `simulate` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(io)\n",
    "assim_data = stimulus.randn(cf)\n",
    "assim_data = io.merge_data(simulate.multivariate_glm(cf, assim_data))\n",
    "t_stim = np.arange(0, cf.data.stimulus.duration, cf.data.dt)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6, 4))\n",
    "axes[0].imshow(assim_data[\"stim\"], extent=(0, cf.data.stimulus.duration, 0, cf.data.filter.ntau), \n",
    "               origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, assim_data[\"V\"])\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(1000, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "First we'll estimate the full RF (using the raised cosine basis set to compress time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "try:\n",
    "    mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "%time w0 = mlest.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.as_matrix(w0[3:], kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reduce parameter counts by factorizing the STRF (as in Thorson et al). This doesn't make much of a difference with white noise stimuli but it can really help when there are strong correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krank = 1\n",
    "mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "%time w0 = mlest.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stim = stimulus.randn(cf, random_seed=1000)\n",
    "test_data = io.merge_data(simulate.multivariate_glm(cf, test_stim, random_seed=1000, trials=10))\n",
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                     test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True)\n",
    "axes[0].imshow(test_data[\"stim\"], extent=(0, cf.data.stimulus.duration, 0, cf.data.filter.ntau), \n",
    "               origin='lower', aspect='auto')\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "V = strf.convolve(test_data[\"stim\"], k1)\n",
    "Vpred = mltest.V(w0)\n",
    "axes[1].plot(t_stim, V, t_stim, Vpred)\n",
    "\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[2].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "upsample = int(cf.data.dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "axes[3].plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "axes[3].set_xlim(0, 2000);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % np.corrcoef(test_psth, pred_psth)[0, 1])\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
