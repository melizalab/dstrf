{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: multivariate song stimulus, biophysical dynamics\n",
    "\n",
    "This demo corresponds to the main analysis in the paper. It simulates responses to song using a linear-dynamical cascade model and then estimates GLM parameters from the responses. Please note, like all of the other demos this is here for informative purposes only - there may be some differences with the `assimilate.py` and `predict.py` scripts used for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import io, strf, mle, simulate, data, filters, models, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up parameters using YAML and Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 50\n",
    "    ncos: 12\n",
    "  prior:\n",
    "    l1: 585.0558005127248\n",
    "    l2: 30.792410553301334\n",
    "data:\n",
    "  source: \"wavefiles\"\n",
    "  root: \"../../zf_songs\"\n",
    "  stimulus:\n",
    "    spectrogram:\n",
    "      window: 2.5\n",
    "      compress: 10\n",
    "      f_min: 1.0\n",
    "      f_max: 8.0\n",
    "      f_count: 20\n",
    "      gammatone: True\n",
    "  model: \"multivariate_dynamical\"\n",
    "  dynamics:\n",
    "    model: \"../../models/phasic.yml\"\n",
    "    current_scaling: 4.0\n",
    "    current_compression:\n",
    "      intercept: -1.32215976\n",
    "      slope: 0.04068182\n",
    "      V_lower: -100\n",
    "      V_upper: 0\n",
    "    current_recenter: 1.0\n",
    "  filter:\n",
    "    # the hg_dstrf filter function loads parameters from a file; select which row to use with `rf`\n",
    "    fn: \"hg_dstrf\"\n",
    "    paramfile: \"../../config/hg_filters.csv\"\n",
    "    rf: 0\n",
    "    nfreq: 20\n",
    "    ntau: 50\n",
    "    t_max: 50\n",
    "    ampl: 1.0\n",
    "    f_max: 8\n",
    "    Pf: 0.0\n",
    "  trial_noise:\n",
    "    color: pink\n",
    "    snr: 4\n",
    "    random_seed: 1049\n",
    "  dt: 1.0\n",
    "  trials: 3\n",
    "  test_proportion: 0.2\n",
    "spike_detect:\n",
    "  thresh: -20.0\n",
    "  rise_dt: 1.0\n",
    "emcee:\n",
    "  nsteps: 10\n",
    "  nthreads: 8\n",
    "  nwalkers: 500\n",
    "  startpos_scale: 2.0\n",
    "  bounds:\n",
    "  - [0, 20]\n",
    "  - [-50, 800]\n",
    "  - [-5, 10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k1, k1t, k1f = simulate.get_filter(cf)\n",
    "plt.imshow(k1, extent=(k1t[0], k1t[-1], k1f[0], k1f[-1]), cmap='jet', aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code has been factored out to the `simulate` module. We're going to split the data into assimilation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stim_data = data.wavefiles(cf)\n",
    "n_test = int(cf.data.test_proportion * len(stim_data))\n",
    "assim_data = io.merge_data(simulate.multivariate_dynamical(cf, stim_data[:-n_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"duration:\", assim_data[\"duration\"])\n",
    "print(\"stim bins:\", assim_data[\"stim\"].shape[1])\n",
    "print(\"spike bins:\", assim_data[\"spike_v\"].shape[0])\n",
    "print(\"I_max:\", np.max(assim_data[\"I\"]))\n",
    "print(\"I_rms:\", np.sqrt((assim_data[\"I\"] ** 2).mean()))\n",
    "print(\"total spikes:\", np.sum(assim_data[\"spike_v\"]))\n",
    "print(\"avg spike rate:\", 1000 * np.sum(assim_data[\"spike_v\"]) / assim_data[\"duration\"] / assim_data[\"spike_v\"].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_stim = np.linspace(0, assim_data[\"duration\"], assim_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, assim_data[\"duration\"], assim_data[\"spike_v\"].shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(6, 9))\n",
    "axes[0].imshow(assim_data[\"stim\"], \n",
    "               extent=(0, assim_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, assim_data[\"I\"])\n",
    "axes[2].plot(t_spike, assim_data[\"V\"])\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    axes[3].vlines(spk * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(0, 4000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "Uncomment the next cell if you want to use the full-rank estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "# try:\n",
    "#     mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "#                         assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "# except TypeError:\n",
    "#     mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "#                         assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell constructs the reduced-rank (factorized) estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "krank = cf.model.filter.rank\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "try:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reg_alpha and reg_lambda parameters set the L1 and L2 penalties for elastic-net regularization. As in the previous demo, we're just going to pick some reasonable values. You'll need to use the `assimilate.py` script if you want to use cross-validation to find the optimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time w0 = mlest.estimate(reg_lambda=cf.model.prior.l2, reg_alpha=cf.model.prior.l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "#rf_mle = strf.as_matrix(w0[3:], kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data = io.merge_data(simulate.multivariate_dynamical(cf, stim_data[-n_test:], trials=50))\n",
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                     test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"duration:\", test_data[\"duration\"])\n",
    "print(\"stim bins:\", test_data[\"stim\"].shape[1])\n",
    "print(\"spike bins:\", test_data[\"spike_v\"].shape[0])\n",
    "print(\"I_max:\", np.max(test_data[\"I\"]))\n",
    "print(\"I_rms:\", np.sqrt((test_data[\"I\"] ** 2).mean()))\n",
    "print(\"total spikes:\", np.sum(test_data[\"spike_v\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(6, 9))\n",
    "axes[0].imshow(test_data[\"stim\"], \n",
    "               extent=(0, test_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "#V = strf.convolve(test_data[\"stim\"], k1)\n",
    "Vpred = mltest.V(w0)\n",
    "axes[1].plot(t_spike, test_data[\"V\"], t_stim, Vpred)\n",
    "\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[2].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "psth_dt = 5\n",
    "upsample = int(psth_dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "t_psth = np.linspace(0, test_data[\"duration\"], test_psth.size)\n",
    "axes[3].plot(t_psth, test_psth, t_psth, pred_psth)\n",
    "axes[3].set_xlim(0, 2000);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "cc = performance.corrcoef(test_data[\"spike_v\"], pred, upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % cc)\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
