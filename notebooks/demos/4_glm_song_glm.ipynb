{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: multivariate song stimulus\n",
    "\n",
    "This demo estimates GLM parameters using song stimuli. The song waveform is processed to a 2D spectrogram, then convolved with a 2D STRF to produce the \"voltage\" of the GLM model. The adaptation \"current\" is calculated by convolving the spike trains with two exponential kernels. The goal of the assimilation is to estimate the parameters of the RF and the adaptation kernels. The parameter count of the RF is minimized by using a low-rank approximation (i.e., an outer product of two vectors) and by projecting time into a basis set of raised cosine filters that are spaced exponentially.\n",
    "\n",
    "This notebook also demonstrates the use of elastic-net penalized maximum-likelihood estimation to regularize parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import io, strf, mle, simulate, stimulus, filters, models, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up parameters using YAML and Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 30\n",
    "    ncos: 8\n",
    "  prior:\n",
    "    l1: 10.0\n",
    "    l2: 10.0\n",
    "data:\n",
    "  stimulus:\n",
    "    source: \"crcns\"\n",
    "    root: \"/home/data/crcns\"\n",
    "    cell: \"blabla0903_2_B\"\n",
    "    stim_type: \"conspecific\"\n",
    "    spectrogram:\n",
    "      window: 2.5\n",
    "      compress: 10\n",
    "      f_min: 0\n",
    "      f_max: 8000\n",
    "      gammatone: False\n",
    "  model: \"multivariate_glm\"\n",
    "  filter:\n",
    "    fn: \"hg\"\n",
    "    nfreq: 20\n",
    "    ntau: 30\n",
    "    ampl: 0.75\n",
    "    f_max: 8000\n",
    "    f_peak: 2844\n",
    "    f_sigma: 1504\n",
    "    f_omega: 0.0001329\n",
    "    t_max: 30\n",
    "    t_peak: 8.19517332914\n",
    "    t_sigma: 4.3656196941\n",
    "    t_omega: 0.04398\n",
    "    Pt: 1.571\n",
    "    Pf: 0.0\n",
    "  adaptation: [7.0, 100.0, 2.0]\n",
    "  trial_noise:\n",
    "    sd: 2.0\n",
    "  random_seed: 1\n",
    "  dt: 3.0\n",
    "  trials: 5\n",
    "  test_proportion: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, _, _ = filters.hg(**cf.data.filter)\n",
    "plt.imshow(k1, cmap='jet', aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code has been factored out to the `simulate` module. We're going to split the data into assimilation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = stimulus.crcns(cf)\n",
    "n_test = int(cf.data.test_proportion * len(stim_data))\n",
    "\n",
    "assim_data = io.merge_data(simulate.multivariate_glm(cf, stim_data[:-n_test]))\n",
    "test_data = io.merge_data(simulate.multivariate_glm(cf, stim_data[-n_test:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration:\", assim_data[\"duration\"])\n",
    "print(\"stim bins:\", assim_data[\"stim\"].shape[1])\n",
    "print(\"spike bins:\", assim_data[\"spike_v\"].shape[0])\n",
    "print(\"total spikes:\", np.sum(assim_data[\"spike_v\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stim = np.linspace(0, assim_data[\"duration\"], assim_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, assim_data[\"duration\"], assim_data[\"spike_v\"].shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6, 4))\n",
    "axes[0].imshow(assim_data[\"stim\"], \n",
    "               extent=(0, assim_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, assim_data[\"V\"])\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(0, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "Construct the factorized ML estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "krank = cf.model.filter.rank\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "try:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reg_alpha and reg_lambda parameters set the L1 and L2 penalties for the initial ML estimation. We'll start with some fairly moderate regularization just to get an initial estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time w0 = mlest.estimate(reg_lambda=cf.model.prior.l2, reg_alpha=cf.model.prior.l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to select regularization parameters using cross-validation. This makes use of the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from dstrf import crossvalidate\n",
    "\n",
    "#reg_grid = np.logspace(-1, 5, 50)[::-1]\n",
    "l1_ratios = [0.1, 0.5, 0.7, 0.9, 0.95]\n",
    "reg_grid = np.logspace(-1, 5, 20)[::-1]\n",
    "scores = []\n",
    "results = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(l1_ratios) * len(reg_grid),\n",
    "                              widgets=[\n",
    "                                ' [', progressbar.Timer(), '] ',\n",
    "                                progressbar.Bar(),\n",
    "                                ' (', progressbar.ETA(), ') ',\n",
    "                            ])\n",
    "for reg, s, w in bar(crossvalidate.elasticnet(mlest, 4, reg_grid, l1_ratios, avextol=1e-5, disp=False)):\n",
    "    scores.append(s)\n",
    "    results.append((reg, s, w))\n",
    "    \n",
    "best_idx = np.argmax(scores)\n",
    "(rf_alpha, rf_lambda), ll, w0 = results[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"best regularization params: alpha={}, lambda={}\".format(rf_alpha, rf_lambda))\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                     test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True)\n",
    "axes[0].imshow(assim_data[\"stim\"], \n",
    "               extent=(0, test_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "V = strf.convolve(test_data[\"stim\"], k1)\n",
    "Vpred = mltest.V(w0)\n",
    "axes[1].plot(t_stim, V, t_stim, Vpred)\n",
    "\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[2].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "upsample = int(cf.data.dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "axes[3].plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "axes[3].set_xlim(0, 2000);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % np.corrcoef(test_psth, pred_psth)[0, 1])\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
