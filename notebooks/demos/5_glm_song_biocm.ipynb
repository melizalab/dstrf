{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: multivariate song stimulus, biophysical dynamics\n",
    "\n",
    "This demo adds biophysical dynamics to the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import io, strf, mle, simulate, stimulus, filters, models, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up parameters using YAML and Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 50\n",
    "    ncos: 12\n",
    "  prior:\n",
    "    l1: 50\n",
    "    l2: 5\n",
    "data:\n",
    "  stimulus:\n",
    "    source: \"crcns\"\n",
    "    root: \"../../crcns\"\n",
    "    spectrogram:\n",
    "      window: 2.5\n",
    "      compress: 10\n",
    "      f_min: 0\n",
    "      f_max: 8.0\n",
    "      f_count: 20\n",
    "      gammatone: False\n",
    "  model: \"multivariate_dynamical\"\n",
    "  dynamics:\n",
    "    model: \"../../models/posp.yml\"\n",
    "    current_scaling: 1.0\n",
    "  filter:\n",
    "    fn: \"hg_dstrf\"\n",
    "    paramfile: \"../../config/hg_filters.csv\"\n",
    "    rf: 14\n",
    "    nfreq: 20\n",
    "    ntau: 50\n",
    "    t_max: 50\n",
    "    ampl: 0.2\n",
    "    f_max: 8\n",
    "    Pf: 0.0\n",
    "  trial_noise:\n",
    "    color: pink\n",
    "    snr: 2\n",
    "  random_seed: 1\n",
    "  dt: 1.0\n",
    "  trials: 10\n",
    "  test_proportion: 0.2\n",
    "spike_detect:\n",
    "  thresh: -20.0\n",
    "  rise_dt: 1.0\n",
    "emcee:\n",
    "  nsteps: 10\n",
    "  nthreads: 8\n",
    "  nwalkers: 500\n",
    "  startpos_scale: 2.0\n",
    "  bounds:\n",
    "  - [0, 20]\n",
    "  - [-50, 200]\n",
    "  - [-5, 10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k1, k1t, k1f = simulate.get_filter(cf)\n",
    "plt.imshow(k1, extent=(k1t[0], k1t[-1], k1f[0], k1f[-1]), cmap='jet', aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code has been factored out to the `simulate` module. We're going to split the data into assimilation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = stimulus.crcns(cf)\n",
    "n_test = int(cf.data.test_proportion * len(stim_data))\n",
    "\n",
    "assim_data = io.merge_data(simulate.multivariate_dynamical(cf, stim_data[:-n_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duration:\", assim_data[\"duration\"])\n",
    "print(\"stim bins:\", assim_data[\"stim\"].shape[1])\n",
    "print(\"spike bins:\", assim_data[\"spike_v\"].shape[0])\n",
    "print(\"I_max:\", np.max(assim_data[\"I\"]))\n",
    "print(\"I_rms:\", np.sqrt((assim_data[\"I\"] ** 2).mean()))\n",
    "print(\"total spikes:\", np.sum(assim_data[\"spike_v\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stim = np.linspace(0, assim_data[\"duration\"], assim_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, assim_data[\"duration\"], assim_data[\"spike_v\"].shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(6, 9))\n",
    "axes[0].imshow(assim_data[\"stim\"], \n",
    "               extent=(0, assim_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, assim_data[\"I\"])\n",
    "axes[2].plot(t_spike, assim_data[\"V\"])\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    axes[3].vlines(spk * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(0, 2000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "Construct the factorized ML estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "krank = cf.model.filter.rank\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "try:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reg_alpha and reg_lambda parameters set the L1 and L2 penalties for the initial ML estimation. We'll start with some fairly moderate regularization just to get an initial estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time w0 = mlest.estimate(reg_lambda=cf.model.prior.l2, reg_alpha=cf.model.prior.l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to select regularization parameters using cross-validation. This makes use of the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from dstrf import crossvalidate\n",
    "\n",
    "#reg_grid = np.logspace(-1, 5, 50)[::-1]\n",
    "l1_ratios = [0.1, 0.5, 0.7, 0.9, 0.95]\n",
    "reg_grid = np.logspace(-1, 5, 20)[::-1]\n",
    "scores = []\n",
    "results = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(l1_ratios) * len(reg_grid),\n",
    "                              widgets=[\n",
    "                                ' [', progressbar.Timer(), '] ',\n",
    "                                progressbar.Bar(),\n",
    "                                ' (', progressbar.ETA(), ') ',\n",
    "                            ])\n",
    "for reg, s, w in bar(crossvalidate.elasticnet(mlest, 4, reg_grid, l1_ratios, avextol=1e-5, disp=False)):\n",
    "    scores.append(s)\n",
    "    results.append((reg, s, w))\n",
    "    \n",
    "best_idx = np.argmax(scores)\n",
    "(rf_alpha, rf_lambda), ll, w0 = results[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best regularization params: alpha={}, lambda={}\".format(rf_alpha, rf_lambda))\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = io.merge_data(simulate.multivariate_dynamical(cf, stim_data[-n_test:]))\n",
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                     test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True)\n",
    "axes[0].imshow(assim_data[\"stim\"], \n",
    "               extent=(0, test_data[\"duration\"], cf.data.stimulus.spectrogram.f_min, cf.data.stimulus.spectrogram.f_max),\n",
    "               cmap='jet', origin='lower', aspect='auto')\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "#V = strf.convolve(test_data[\"stim\"], k1)\n",
    "Vpred = mltest.V(w0)\n",
    "axes[1].plot(t_spike, test_data[\"V\"], t_stim, Vpred)\n",
    "\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[2].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "psth_dt = 5\n",
    "upsample = int(psth_dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "t_psth = np.linspace(0, test_data[\"duration\"], test_psth.size)\n",
    "axes[3].plot(t_psth, test_psth, t_psth, pred_psth)\n",
    "axes[3].set_xlim(0, 2000);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "cc = performance.corrcoef(test_data[\"spike_v\"], pred, upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % cc)\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
