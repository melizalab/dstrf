{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: multivariate noise stimulus\n",
    "\n",
    "This is a demo notebook for the GLM estimation algorithm. We simulate data using the GLM, and then try to estimate parameters with the GLM. This notebook demos the use of a multivariate stimulus like a spectrogram, although the stimulus used here is more like 1D visual white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle, simulate, filters, models\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "cfg = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up parameters using YAML and Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 30\n",
    "    ncos: 8\n",
    "data:\n",
    "  filter:\n",
    "    fn: \"gabor\"\n",
    "    nfreq: 14\n",
    "    ntau: 30\n",
    "    f_max: 8000\n",
    "    f_peak: 4000\n",
    "    t_peak: 12\n",
    "    ampl: -1\n",
    "    t_sigma: 6\n",
    "    f_sigma: 2400\n",
    "    theta: 0\n",
    "    lmbda: 19\n",
    "    psi: 1.5\n",
    "  adaptation: [7.0, 100.0, 2.0]\n",
    "  trial_noise:\n",
    "    sd: 2.0\n",
    "  random_seed: 1\n",
    "  dt: 10.0\n",
    "  duration: 400000\n",
    "  trials: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, _, _ = filters.gabor(**cf.data.filter)\n",
    "plt.imshow(k1, cmap='jet', aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code has been factored out to the `simulate` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assim_data = simulate.multivariate_noise_glm(cf)\n",
    "t_stim = np.arange(0, cf.data.duration, cf.data.dt)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6, 4))\n",
    "axes[0].imshow(assim_data[0][\"stim\"], extent=(0, cf.data.duration, 0, cf.data.filter.ntau), \n",
    "               origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, assim_data[0][\"V\"])\n",
    "for i, d in enumerate(assim_data):\n",
    "    axes[2].vlines(d[\"spike_t\"] * cf.model.dt, i, i + 0.5)\n",
    "\n",
    "axes[0].set_xlim(0, 5000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "First we'll estimate the full RF (using the raised cosine basis set to compress time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "kcosbas = strf.cosbasis(cf.model.filter.len, cf.model.filter.ncos)\n",
    "stim_dt = cf.data.dt\n",
    "model_dt = cf.model.dt\n",
    "stim = assim_data[0][\"stim\"]\n",
    "spike_v = np.stack([d[\"spike_v\"] for d in assim_data], axis=1)\n",
    "spike_h = np.stack([d[\"H\"] for d in assim_data], axis=2)\n",
    "try:\n",
    "    mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "except TypeError:\n",
    "    mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "%time w0 = mlest.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.as_matrix(w0[3:], kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reduce parameter counts by factorizing the STRF (as in Thorson et al). This doesn't make much of a difference with white noise stimuli but it can really help when there are strong correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krank = 1\n",
    "mlest = mle.matfact(stim, kcosbas, krank, spike_v, spike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "%time w0 = mlest.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], cf.data.filter.nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE (rank-{})\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trials = 10\n",
    "test_data = simulate.multivariate_noise_glm(cf, random_seed=1000, trials=test_trials)\n",
    "tstim = test_data[0][\"stim\"]\n",
    "tspike_v = np.stack([d[\"spike_v\"] for d in test_data], axis=1)\n",
    "tspike_h = np.stack([d[\"H\"] for d in test_data], axis=2)\n",
    "\n",
    "mltest = mle.matfact(tstim, kcosbas, krank, tspike_v, tspike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6, 4))\n",
    "axes[0].imshow(assim_data[0][\"stim\"], extent=(0, cf.data.duration, 0, cf.data.filter.ntau), \n",
    "               origin='lower', aspect='auto')\n",
    "axes[1].plot(t_stim, test_data[0][\"V\"])\n",
    "for i in range(test_trials):\n",
    "    V = mltest.V(w0)\n",
    "    S = models.predict_spikes_glm(V, w0[:3], cf)\n",
    "    axes[2].vlines(S.nonzero()[0] * model_dt, i - 0.4, i + 0.4)\n",
    "for i, d in enumerate(test_data):\n",
    "    axes[2].vlines(d[\"spike_t\"] * model_dt, i - 0.4 + test_trials, i + 0.4 + test_trials, color=\"r\")\n",
    "\n",
    "axes[2].set_xlim(0, 5000);"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
