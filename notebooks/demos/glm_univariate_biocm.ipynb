{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Demo: univariate stimulus, biophysical dynamics\n",
    "\n",
    "This is a demo notebook for the GLM estimation algorithm. Here we simulate data using the biophysical dynamical cascade model, and then try to estimate parameters with the GLM. The GLM does not have a membrane, so the estimated RF should be the convolution of the input kernel ($k1$) with the membrane kernel ($k2$) which is approximately an exponential decay with time constant $\\tau_m$. However, what can happen is that the kernel gets shifted to shorter lags for the phasic model, which is consistent with what Chen and Meliza (2018) found for the coherence between an input current and the spiking output - the dynamics act as a bandpass filter.\n",
    "\n",
    "This notebook also introduces the use of a raised cosine basis set to reduce the number of parameters in the kernel estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import imp\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sps\n",
    "import quickspikes as qs\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle, filters\n",
    "import spyks.core as spkc\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = 0.5\n",
    "stim_dt = 10.0\n",
    "\n",
    "# decay times for exponential adaptation basis set\n",
    "ataus = np.asarray([10, 200], dtype='d')\n",
    "\n",
    "# convolution kernel\n",
    "ntau = 60\n",
    "upsample = int(stim_dt / model_dt)\n",
    "ntbas = 8\n",
    "\n",
    "k1, kt = filters.gammadiff(ntau * stim_dt / 32, ntau * stim_dt / 16, 10.0, ntau * stim_dt, stim_dt)\n",
    "plt.plot(kt, k1)\n",
    "\n",
    "# raised-cosine basis functions\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "ntbas = kcosbas.shape[1]\n",
    "k1c = strf.to_basis(k1, kcosbas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the stimulus and response\n",
    "\n",
    "We are also using gaussian white noise here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating spikes with biocm\n",
    "# this needs to be adjusted on a per model basis. posp ~ 2.0; phasic ~ 10\n",
    "# model_name = \"biocm_phasic\"\n",
    "# current_scaling = 9.0\n",
    "model_name = \"biocm_tonic\"\n",
    "current_scaling = 4.0\n",
    "# model_name = \"pospischil_sm\"\n",
    "# current_scaling = 2.0\n",
    "\n",
    "trial_noise_sd = 2.0\n",
    "spike_thresh = -20\n",
    "dt_rise_time = int(1.0 / model_dt)\n",
    "modelpath = \"../../models\"\n",
    "pymodel = spkc.load_model(os.path.join(modelpath, model_name + \".yml\"))\n",
    "biocm_params = spkc.to_array(pymodel[\"parameters\"])\n",
    "biocm_state0 = spkc.to_array(pymodel[\"state\"])\n",
    "biocm_model = spkc.load_module(pymodel, modelpath)\n",
    "    \n",
    "def filter_stimulus(S, k1):\n",
    "    return np.convolve(S, k1, mode=\"full\")[:S.size]\n",
    "\n",
    "def generate_spikes(I, noise_sd, dt, upsample):\n",
    "    from scipy.signal import resample\n",
    "    I_noise = np.random.randn(I.size) * noise_sd\n",
    "    I = current_scaling * (I + I_noise)\n",
    "    #I_resamp = sps.resample(I + I_noise, I.size * upsample)\n",
    "    X = biocm_model.integrate(biocm_params, biocm_state0, I, stim_dt, model_dt)\n",
    "    det = qs.detector(spike_thresh, dt_rise_time)\n",
    "    return I, X[:, 0], det(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "duration = 100000\n",
    "n_bins = int(duration / model_dt)\n",
    "n_frames = n_bins // upsample\n",
    "n_assim = 10\n",
    "n_test = 10\n",
    "\n",
    "# generate data to fit\n",
    "np.random.seed(1)\n",
    "mat.random_seed(1)\n",
    "data = []\n",
    "stim = np.random.randn(n_frames)\n",
    "stim[:100] = 0\n",
    "        \n",
    "I = filter_stimulus(stim, k1)\n",
    "for i in range(n_assim):\n",
    "    In, V, spike_t = generate_spikes(I, trial_noise_sd, model_dt, upsample)\n",
    "    spike_v = np.zeros(V.size, 'i')\n",
    "    spike_v[spike_t] = 1\n",
    "    H = mat.adaptation(spike_v, ataus, model_dt)\n",
    "    d = {\"H\": H,\n",
    "         \"duration\": duration,\n",
    "         \"spike_t\": np.asarray(spike_t), \n",
    "         \"spike_v\": spike_v,\n",
    "        }\n",
    "    data.append(d)\n",
    "\n",
    "# split into assimilation and test sets\n",
    "assim_data = data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(9, 4))\n",
    "t_stim = np.linspace(0, duration, stim.size)\n",
    "t_voltage = np.linspace(0, duration, V.size)\n",
    "axes[0].set_title(\"Simulated {} response\".format(model_name))\n",
    "axes[0].plot(t_stim, stim)\n",
    "axes[1].plot(t_stim, I, t_voltage, V)\n",
    "for i, d in enumerate(data):\n",
    "    axes[2].vlines(d[\"spike_t\"] * model_dt, i, i + 0.5)\n",
    "for ax in axes:\n",
    "    ax.set_xlim(0, 8000)\n",
    "print(\"spikes: {}; rate: {} / dt\".format(np.mean([d[\"spike_t\"].size for d in data]), \n",
    "                                         np.mean([d[\"spike_t\"].size / d[\"duration\"] for d in data])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "The theano code for setting up maximum likelihood estimation has been factored out into the `mle` package.\n",
    "\n",
    "**Note**: The following cell sometimes generates an error the first time you run it. Just run it again if that happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using regularized ML\n",
    "ntbas = 8\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "spike_v = np.stack([d[\"spike_v\"] for d in assim_data], axis=1)\n",
    "spike_h = np.stack([d[\"H\"] for d in assim_data], axis=2)\n",
    "try:\n",
    "    mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "except TypeError:\n",
    "    mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"exp\")\n",
    "%time w0 = mlest.estimate(reg_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "rf_ml = strf.from_basis(w0[3:], kcosbas)[::-1]\n",
    "plt.plot(k1, label=\"kernel\")\n",
    "\n",
    "# there is an expected shift due to the filtering properties of the membrane\n",
    "km, kmt = filters.exponential(46, 1.0, ntau * stim_dt, stim_dt)\n",
    "kconv = np.convolve(km, k1, mode=\"full\")[:km.size]\n",
    "kconv *= k1.max() / kconv.max()\n",
    "plt.plot(kconv, label=\"expected\")\n",
    "\n",
    "plt.plot(rf_ml * k1.max() / rf_ml.max(), label=\"MLE\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
