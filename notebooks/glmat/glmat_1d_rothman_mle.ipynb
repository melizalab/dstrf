{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a testing notebook for the GLMAT estimation algorithm. We simulate data using the rothman dSTRF model, and then try to estimate parameters with the GLMAT model. The GLMAT model does not have a membrane, so the estimated RF should be the convolution of the input kernel ($k1$) with the membrane kernel ($k2$) which is approximately an exponential decay with time constant $\\tau_m$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sps\n",
    "import quickspikes as qs\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle\n",
    "import spyks.core as spkc\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters: (\u03c9, \u03b11, \u03b12, \u03c41, \u03c42, tref)\n",
    "matparams = np.asarray([7, 100, 2, 10, 200, 2], dtype='d')\n",
    "model_dt = 0.5\n",
    "\n",
    "# convolution kernel\n",
    "from dstrf import filters\n",
    "stim_dt = 10.0\n",
    "kscale = 1.0\n",
    "ntau = 60\n",
    "upsample = int(stim_dt / model_dt)\n",
    "k1, kt = filters.gammadiff(ntau * stim_dt / 32, ntau * stim_dt / 16, 5 * kscale, ntau * stim_dt, stim_dt)\n",
    "#k1, kt = filters.exponential(ntau * stim_dt / 4, 500 * kscale, ntau * stim_dt, stim_dt)\n",
    "plt.plot(kt, k1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating spikes with biocm\n",
    "model_name = \"biocm_phasic.yml\"\n",
    "# this needs to be adjusted on a per model basis. posp ~ 2.0; phasic ~ 10\n",
    "current_scaling = 20.0\n",
    "trial_noise_sd = 1.0\n",
    "spike_thresh = -20\n",
    "dt_rise_time = int(1.0 / model_dt)\n",
    "modelpath = \"../../models\"\n",
    "pymodel = spkc.load_model(os.path.join(modelpath, model_name))\n",
    "biocm_params = spkc.to_array(pymodel[\"parameters\"])\n",
    "biocm_state0 = spkc.to_array(pymodel[\"state\"])\n",
    "biocm_model = spkc.load_module(pymodel, modelpath)\n",
    "    \n",
    "def filter_stimulus(S, k1):\n",
    "    return np.convolve(S, k1, mode=\"full\")[:S.size]\n",
    "\n",
    "def generate_spikes(I, noise_sd, dt, upsample):\n",
    "    from scipy.signal import resample\n",
    "    I_noise = np.random.randn(I.size) * noise_sd\n",
    "    I = current_scaling * (I + I_noise)\n",
    "    #I_resamp = sps.resample(I + I_noise, I.size * upsample)\n",
    "    X = biocm_model.integrate(biocm_params, biocm_state0, I, stim_dt, model_dt)\n",
    "    det = qs.detector(spike_thresh, dt_rise_time)\n",
    "    return X[:, 0], det(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "duration = 100000\n",
    "n_bins = int(duration / model_dt)\n",
    "n_frames = n_bins // upsample\n",
    "n_assim = 1\n",
    "n_test = 5\n",
    "\n",
    "# generate data to fit\n",
    "np.random.seed(1)\n",
    "mat.random_seed(1)\n",
    "data = []\n",
    "stim = np.random.randn(n_frames)\n",
    "#stim[:100] = 0\n",
    "        \n",
    "I = filter_stimulus(stim, k1)\n",
    "plt.plot(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_assim + n_test):\n",
    "    V, spike_t = generate_spikes(I, trial_noise_sd, model_dt, upsample)\n",
    "    spike_v = np.zeros(V.size, 'i')\n",
    "    spike_v[spike_t] = 1\n",
    "    H = mat.adaptation(spike_v, matparams[3:5], model_dt)\n",
    "    d = {\"H\": H,\n",
    "         \"duration\": duration,\n",
    "         \"spike_t\": np.asarray(spike_t), \n",
    "         \"spike_v\": spike_v,\n",
    "        }\n",
    "    data.append(d)\n",
    "\n",
    "# split into assimilation and test sets\n",
    "assim_data = data[:n_assim]\n",
    "test_data = data[n_assim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stim = np.linspace(0, duration, stim.size)\n",
    "t_voltage = np.linspace(0, duration, V.size)\n",
    "plt.subplot(311).plot(t_stim, stim)\n",
    "plt.subplot(312).plot(t_stim, I, t_voltage, V)\n",
    "ax2 = plt.subplot(313)\n",
    "for i, d in enumerate(data):\n",
    "    ax2.vlines(d[\"spike_t\"] * model_dt, i, i + 0.5)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 8000)\n",
    "print(\"spikes: {}; rate: {} / dt\".format(np.mean([d[\"spike_t\"].size for d in data]), \n",
    "                                         np.mean([d[\"spike_t\"].size / d[\"duration\"] for d in data])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano import config\n",
    "import scipy.optimize as op\n",
    "\n",
    "# cosine basis set\n",
    "kcosbas = strf.cosbasis(ntau, 10)\n",
    "kcosbas = ntau\n",
    "\n",
    "ftype = config.floatX\n",
    "# combine the trials\n",
    "spike_v = np.stack([d[\"spike_v\"] for d in assim_data], axis=1)\n",
    "# spikes in the exponential basis set\n",
    "X_spikes = np.stack([d[\"H\"] for d in assim_data], axis=2).astype(ftype)\n",
    "# generate design matrix for stimulus\n",
    "X_stim = strf.lagged_matrix(stim, kcosbas)\n",
    "# \"correct\" strf from current\n",
    "stx = np.dot(X_stim.T, I) / I.size / stim.var()\n",
    "# initial guess of strf from sta\n",
    "sta = strf.correlate(X_stim, spike_v)\n",
    "\n",
    "plt.plot(k1)\n",
    "plt.plot(strf.from_basis(stx, kcosbas)[::-1])\n",
    "plt.plot(strf.from_basis(sta, kcosbas)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano import function, config, shared, sparse, gradient\n",
    "import theano.tensor as T\n",
    "from theano.tensor import nnet\n",
    "import scipy.sparse as sps\n",
    "\n",
    "# the nonlinearity:\n",
    "nlin = T.exp\n",
    "\n",
    "if X_spikes.ndim == 2:\n",
    "    spike_design = np.expand_dims(X_spikes, 2)\n",
    "\n",
    "nframes, nk = X_stim.shape\n",
    "nbins, nalpha, ntrials = X_spikes.shape\n",
    "upsample = int(stim_dt / model_dt)\n",
    "# make an interpolation matrix\n",
    "interp = sps.kron(sps.eye(nframes),\n",
    "                  np.ones((upsample, 1), dtype=config.floatX),\n",
    "                  format='csc')\n",
    "\n",
    "\n",
    "# load the data into theano.shared structures\n",
    "M = shared(interp)\n",
    "dt = shared(model_dt)\n",
    "Xstim = shared(X_stim)\n",
    "Xspke = shared(np.rollaxis(X_spikes, 2))\n",
    "spikes = sps.csc_matrix(spike_v)\n",
    "Yspke = shared(spikes)\n",
    "\n",
    "# split out the parameter vector\n",
    "w = T.vector('w')\n",
    "dc = w[0]\n",
    "h = w[1:(nalpha+1)]\n",
    "k = w[(nalpha+1):]\n",
    "Vx = T.dot(Xstim, k)\n",
    "# Vx has to be promoted to a matrix for structured_dot to work\n",
    "Vi = sparse.structured_dot(M, T.shape_padright(Vx))\n",
    "H = T.dot(Xspke, h).T\n",
    "mu = Vi - H - dc\n",
    "lmb = nlin(mu)\n",
    "# this version of the log-likelihood is faster, but the gradient doesn't work\n",
    "llf = lmb.sum() * dt - sparse.sp_sum(sparse.structured_log(Yspke * lmb), sparse_grad=True)\n",
    "# this version has a working gradient\n",
    "ll = lmb.sum() * dt - sparse.sp_sum(Yspke * T.log(lmb), sparse_grad=True)\n",
    "# this is a penalty to keep the model out of the unallowed space\n",
    "penalty = - (h[0] + h[1] * matparams[3] / matparams[4])\n",
    "dL = T.grad(ll, w)\n",
    "# arbitrary vector for hessian-vector product\n",
    "v = T.vector('v')\n",
    "ddLv = T.grad(T.sum(dL * v), w)\n",
    "\n",
    "fV = function([w], Vx)\n",
    "fH = function([w], H)\n",
    "fL = function([w], llf)\n",
    "fgrad = function([w], dL)\n",
    "fhess = function([w, v], ddLv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial likelihood\n",
    "meanrate = spikes.sum(0).mean() / nbins\n",
    "w0 = np.r_[np.exp(meanrate), 0, 0, np.zeros_like(sta)]\n",
    "fL(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_ml = op.fmin_ncg(fL, w0, fgrad, fhess_p=fhess, avextol=1e-6, maxiter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_ml[:3])\n",
    "plt.plot(k1)\n",
    "# expected kernel is the convolution of k1 and k2\n",
    "# k2 = \n",
    "# kconv = np.convolve(k1, k2[::int(stim_dt / model_dt)], mode=\"full\")[:k1.size]\n",
    "# plt.plot(kconv * k1.max() / kconv.max())\n",
    "kest = strf.from_basis(w_ml[3:], kcosbas)[::-1]\n",
    "kest *= k1.max() / kest.max()\n",
    "plt.plot(kest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ff in (k1, kest):\n",
    "    K = np.fft.fft(ff)\n",
    "    plt.plot(np.absolute(K[:K.size//2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive distribution\n",
    "\n",
    "def predict_spikes_current(I, params, dt, upsample):\n",
    "    state = mat.voltage(I, fullmatparams, dt, upsample=upsample)\n",
    "    V = state[:, 0]\n",
    "    return V, predict_spikes_voltage(V, params, dt, 1)\n",
    "\n",
    "def predict_spikes_voltage(V, params, dt, upsample):\n",
    "    omega, a1, a2, t1, t2, tref = params\n",
    "    return mat.predict_poisson(V - omega, (a1, a2), (t1, t2), tref, dt, upsample)\n",
    "\n",
    "for j, d in enumerate(test_data):\n",
    "    plt.vlines(d[\"spike_t\"], j, j + 0.5, 'r')\n",
    "\n",
    "mparamp = matparams.copy()    \n",
    "for i in range(n_test):\n",
    "    V = fV(w_ml)\n",
    "    mparamp[:3] = w_ml[:3]\n",
    "    S = predict_spikes_voltage(V, mparamp, model_dt, upsample)\n",
    "    spk_t = S.nonzero()[0]\n",
    "    plt.vlines(spk_t, i + j + 1, i + j + 1.5)\n",
    "\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to a subset of the data. Need to update shared variables.\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4)\n",
    "i_frames = np.arange(nframes)\n",
    "i_bins = np.arange(nbins)\n",
    "ftrain, ftest = next(kf.split(i_frames))\n",
    "strain, stest = next(kf.split(i_bins))\n",
    "\n",
    "M.set_value(interp[strain][:, ftrain])\n",
    "Xstim.set_value(X_stim[ftrain])\n",
    "Xspke.set_value(np.rollaxis(X_spikes[strain], 2))\n",
    "Yspke.set_value(spikes[strain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_ml = op.fmin_ncg(fL, w0, fgrad, fhess_p=fhess, avextol=1e-6, maxiter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.set_value(interp[stest][:, ftest])\n",
    "Xstim.set_value(X_stim[ftest])\n",
    "Xspke.set_value(np.rollaxis(X_spikes[ftest], 2))\n",
    "Yspke.set_value(spikes[ftest])"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}