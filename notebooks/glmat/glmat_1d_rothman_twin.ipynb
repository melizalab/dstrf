{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a testing notebook for the GLMAT estimation algorithm. We simulate data using the biophysical dSTRF model (biocm or pospischil), and then try to estimate parameters with the GLMAT model. The GLMAT model does not have a membrane, so the estimated RF should be the convolution of the input kernel ($k1$) with the membrane kernel ($k2$) which is approximately an exponential decay with time constant $\\tau_m$. However, what can happen is that the kernel gets shifted to shorter lags for the phasic model, which is consistent with what Chen and Meliza (2018) found for the coherence between an input current and the spiking output - the dynamics act as a bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import imp\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sps\n",
    "import quickspikes as qs\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle\n",
    "import spyks.core as spkc\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters: (\u03c9, \u03b11, \u03b12, \u03c41, \u03c42, tref)\n",
    "matparams = np.asarray([7, 100, 2, 10, 200, 2], dtype='d')\n",
    "model_dt = 0.5\n",
    "\n",
    "matparams_i = [0,1,2]\n",
    "matparams_n = len(matparams_i)\n",
    "matparams_f = matparams[matparams_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convolution kernel\n",
    "from dstrf import filters\n",
    "stim_dt = 10.0\n",
    "ntau = 60\n",
    "upsample = int(stim_dt / model_dt)\n",
    "ntbas = 8\n",
    "kscale = 2.0\n",
    "\n",
    "# raised-cosine basis functions\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "ntbas = kcosbas.shape[1]\n",
    "\n",
    "k1, kt = filters.gammadiff(ntau * stim_dt / 32, ntau * stim_dt / 16, 5, ntau * stim_dt, stim_dt)\n",
    "k1 = k1 * kscale\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "\n",
    "plt.plot(kt, k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generating spikes with biocm\n",
    "# this needs to be adjusted on a per model basis. posp ~ 2.0; phasic ~ 10\n",
    "model_name = \"biocm_phasic.yml\"\n",
    "current_scaling = 9.0\n",
    "model_name = \"biocm_tonic.yml\"\n",
    "current_scaling = 9.0\n",
    "# model_name = \"pospischil_sm.yml\"\n",
    "# current_scaling = 2.0\n",
    "\n",
    "trial_noise_sd = 2.0\n",
    "spike_thresh = -20\n",
    "dt_rise_time = int(1.0 / model_dt)\n",
    "modelpath = \"../../models\"\n",
    "pymodel = spkc.load_model(os.path.join(modelpath, model_name))\n",
    "biocm_params = spkc.to_array(pymodel[\"parameters\"])\n",
    "biocm_state0 = spkc.to_array(pymodel[\"state\"])\n",
    "biocm_model = spkc.load_module(pymodel, modelpath)\n",
    "    \n",
    "def filter_stimulus(S, k1):\n",
    "    return np.convolve(S, k1, mode=\"full\")[:S.size]\n",
    "\n",
    "def generate_spikes(I, noise_sd, dt, upsample):\n",
    "    from scipy.signal import resample\n",
    "    I_noise = np.random.randn(I.size) * noise_sd\n",
    "    I = current_scaling * (I + I_noise)\n",
    "    #I_resamp = sps.resample(I + I_noise, I.size * upsample)\n",
    "    X = biocm_model.integrate(biocm_params, biocm_state0, I, stim_dt, model_dt)\n",
    "    det = qs.detector(spike_thresh, dt_rise_time)\n",
    "    return I, X[:, 0], det(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data parameters\n",
    "duration = 100000\n",
    "n_bins = int(duration / model_dt)\n",
    "n_frames = n_bins // upsample\n",
    "n_assim = 1\n",
    "n_test = 5\n",
    "\n",
    "# generate data to fit\n",
    "np.random.seed(1)\n",
    "mat.random_seed(1)\n",
    "data = []\n",
    "stim = np.random.randn(n_frames)\n",
    "stim[:100] = 0\n",
    "        \n",
    "I = filter_stimulus(stim, k1)\n",
    "for i in range(n_assim + n_test):\n",
    "    In, V, spike_t = generate_spikes(I, trial_noise_sd, model_dt, upsample)\n",
    "    spike_v = np.zeros(V.size, 'i')\n",
    "    spike_v[spike_t] = 1\n",
    "    H = mat.adaptation(spike_v, matparams[3:5], model_dt)\n",
    "    d = {\"H\": H,\n",
    "         \"duration\": duration,\n",
    "         \"spike_t\": np.asarray(spike_t), \n",
    "         \"spike_v\": spike_v,\n",
    "        }\n",
    "    data.append(d)\n",
    "\n",
    "# split into assimilation and test sets\n",
    "assim_data = data[:n_assim]\n",
    "test_data = data[n_assim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(211)\n",
    "ax2 = plt.subplot(212)\n",
    "for i, d in enumerate(data):\n",
    "    ax2.vlines(d[\"spike_t\"], i, i + 0.5)\n",
    "ax1.plot(In)\n",
    "ax1.set_xlim(0, 8000 / upsample)\n",
    "ax2.set_xlim(0, 8000)\n",
    "print(\"spikes: {}; rate: {} / dt\".format(np.mean([d[\"spike_t\"].size for d in data]), \n",
    "                                         np.mean([d[\"spike_t\"].size / d[\"duration\"] for d in data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial guess of parameters using regularized ML\n",
    "ntbas = 8\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "spike_v = np.stack([d[\"spike_v\"] for d in assim_data], axis=1)\n",
    "spike_h = np.stack([d[\"H\"] for d in assim_data], axis=2)\n",
    "mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"softplus\")\n",
    "%time w0 = mlest.estimate(reg_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(w0[:3])\n",
    "rf_sta = strf.from_basis(mlest.sta(), kcosbas)\n",
    "rf_ml = strf.from_basis(w0[3:], kcosbas)[::-1]\n",
    "plt.plot(k1)\n",
    "plt.plot(rf_sta[::-1])\n",
    "plt.plot(rf_ml * k1.max() / rf_ml.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# posterior predictive distribution\n",
    "\n",
    "def predict_spikes_current(I, params, dt, upsample):\n",
    "    state = mat.voltage(I, fullmatparams, dt, upsample=upsample)\n",
    "    V = state[:, 0]\n",
    "    return V, predict_spikes_voltage(V, params, dt, 1)\n",
    "\n",
    "def predict_spikes_voltage(V, params, dt, upsample):\n",
    "    omega, a1, a2, t1, t2, tref = params\n",
    "    return mat.predict_poisson(V - omega, (a1, a2), (t1, t2), tref, dt, upsample)\n",
    "\n",
    "mparamp = matparams.copy()    \n",
    "for i in range(n_test):\n",
    "    V = mlest.V(w0)\n",
    "    mparamp[:3] = w0[:3]\n",
    "    S = predict_spikes_voltage(V, mparamp, model_dt, upsample)\n",
    "    spk_t = S.nonzero()[0]\n",
    "    plt.vlines(spk_t, i, i + 0.5, 'r')\n",
    "\n",
    "for j, d in enumerate(test_data):\n",
    "    plt.vlines(d[\"spike_t\"], i + j + 1, i + j + 1.5, 'k')\n",
    "    \n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimate parameters using emcee\n",
    "from neurofit import priors, costs, utils, startpos\n",
    "import emcee\n",
    "\n",
    "# assimilation parameters\n",
    "if sys.platform == 'darwin':\n",
    "    nthreads = 1\n",
    "else:\n",
    "    nthreads = 8\n",
    "nwalkers = 500\n",
    "nsteps = 500\n",
    "\n",
    "mat_prior = priors.joint_independent(\n",
    "                [ priors.uniform( 0,  20),\n",
    "                  priors.uniform(-50,  200),\n",
    "                  priors.uniform(-5,   10),\n",
    "                ])\n",
    "\n",
    "# lasso prior on RF parameters\n",
    "rf_lambda = 1.0\n",
    "\n",
    "def matbounds(t1, t2, tr):\n",
    "    aa1 = -(1 - np.exp(-tr/t2))/(1 - np.exp(-tr/t1))\n",
    "    aa2 = -(np.exp(tr/t2) - 1)/(np.exp(tr/t1) - 1)\n",
    "    def f(mparams):\n",
    "        return (mparams[2] > aa1 * mparams[1]) and (mparams[2] > aa2 * mparams[1])\n",
    "    return f\n",
    "\n",
    "matboundprior = matbounds(*matparams[3:6])\n",
    "\n",
    "def lnprior(theta):\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    if not matboundprior(mparams):\n",
    "        return -np.inf\n",
    "    rf_prior = -np.sum(np.abs(rfparams)) * rf_lambda\n",
    "    ll = mat_prior(mparams) + rf_prior\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return ll\n",
    "\n",
    "\n",
    "def loglike_poisson(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    return mu[spike_t].sum() - np.exp(mu).sum() * dt \n",
    "\n",
    "\n",
    "def loglike_sigmoid(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    lmb = (1 + np.tanh(mu / 2)) / 2\n",
    "    return np.log(lmb[spike_t]).sum() - lmb.sum() * dt \n",
    "\n",
    "\n",
    "def loglike_softplus(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    lmb = np.log1p(np.exp(mu))\n",
    "    return np.log(lmb[spike_t]).sum() - lmb.sum() * dt \n",
    "    \n",
    "    \n",
    "def lnlike(theta):\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    Vi = mlest.V_interp(theta).squeeze() - mparams[0]\n",
    "    lp = 0\n",
    "    for d in assim_data:\n",
    "        lp += loglike_softplus(Vi, d[\"H\"], d[\"spike_t\"], mparams[1:3], model_dt)\n",
    "    return lp   \n",
    "\n",
    "def lnpost_dyn(theta):\n",
    "    \"\"\"Posterior probability for dynamical parameters\"\"\"\n",
    "    return lnprior(theta) - mlest.loglike(theta) #+ lnlike(theta) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theoretically this is as good as it can get\n",
    "theta_true = np.concatenate([matparams_f, k1c])\n",
    "print(\"lnpost of p_true: {}\".format(lnpost_dyn(theta_true)))\n",
    "# initial state is a gaussian ball around the ML estimate\n",
    "p0 = startpos.normal_independent(nwalkers, w0, np.abs(w0) * 2)\n",
    "theta_0 = np.median(p0, 0)\n",
    "print(\"lnpost of p0 median: {}\".format(lnpost_dyn(theta_0)))\n",
    "%timeit lnpost_dyn(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, theta_true.size, lnpost_dyn, threads=nthreads)\n",
    "tracker = utils.convergence_tracker(nsteps, 25)\n",
    "\n",
    "for pos, prob, _ in tracker(sampler.sample(p0, iterations=nsteps)): \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"lnpost of p median: {}\".format(np.median(prob)))\n",
    "print(\"average acceptance fraction: {}\".format(sampler.acceptance_fraction.mean()))\n",
    "theta = np.median(pos, 0)\n",
    "mparams = theta[:matparams_n]\n",
    "rfparams = theta[matparams_n:]\n",
    "plt.plot(k1)\n",
    "\n",
    "# there is an expected shift due to the filtering properties of the membrane\n",
    "km, kmt = filters.exponential(46, 1.0, ntau * stim_dt, stim_dt)\n",
    "kconv = np.convolve(km, rf_ml, mode=\"full\")[:km.size]\n",
    "plt.plot(kconv * k1.max() / kconv.max())\n",
    "\n",
    "kmap = strf.from_basis(rfparams, kcosbas)[::-1]\n",
    "kmap *= k1.max() / kmap.max()\n",
    "plt.plot(kmap)\n",
    "\n",
    "print(w0[:3])\n",
    "print(theta[:matparams_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ff in (k1, kmap):\n",
    "    K = np.fft.fft(ff)\n",
    "    plt.plot(np.absolute(K[:K.size//2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mpos = pos[:,:matparams_n]\n",
    "matlabs = ['a1','a2','w']\n",
    "c = corner(mpos,\n",
    "           #range=[sp for sp in startparams],\n",
    "       bins=50, smooth=2,smooth1d=0,\n",
    "       labels=matlabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# posterior predictive distribution\n",
    "for j, d in enumerate(test_data):\n",
    "    plt.vlines(d[\"spike_t\"], j, j + 0.5, 'r')\n",
    "\n",
    "mparamp = matparams.copy()\n",
    "samples = np.random.permutation(nwalkers)[:n_test]\n",
    "for i, idx in enumerate(samples):\n",
    "    sample = pos[idx]\n",
    "    V = mlest.V(sample)\n",
    "    mparamp[matparams_i] = sample[:matparams_n]\n",
    "    S = predict_spikes_voltage(V, mparamp, model_dt, upsample)\n",
    "    spk_t = S.nonzero()[0]\n",
    "    plt.vlines(spk_t, i + j + 1, i + j + 1.5)\n",
    "\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}