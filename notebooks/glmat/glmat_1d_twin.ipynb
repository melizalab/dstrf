{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters: (ω, α1, α2, τ1, τ2, tref)\n",
    "matparams = np.asarray([7, 100, 2, 10, 200, 2], dtype='d')\n",
    "model_dt = 0.5\n",
    "\n",
    "matparams_i = [0,1,2]\n",
    "matparams_n = len(matparams_i)\n",
    "matparams_f = matparams[matparams_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convolution kernel\n",
    "from dstrf import filters\n",
    "stim_dt = 10.0\n",
    "ntau = 60\n",
    "upsample = int(stim_dt / model_dt)\n",
    "ntbas = 8\n",
    "kscale = 2.0\n",
    "\n",
    "# raised-cosine basis functions\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "ntbas = kcosbas.shape[1]\n",
    "\n",
    "k1, kt = filters.gammadiff(ntau * stim_dt / 32, ntau * stim_dt / 16, 5, ntau * stim_dt, stim_dt)\n",
    "k1 = k1[::-1] * kscale\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "\n",
    "plt.plot(-kt[::-1], k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_stimulus(S, k1):\n",
    "    return np.correlate(S, k1, mode=\"full\")[:S.size]\n",
    "\n",
    "\n",
    "def predict_spikes(V, params, dt, upsample):\n",
    "    omega, a1, a2, t1, t2, tref = params\n",
    "    return mat.predict_poisson(V - omega, (a1, a2), (t1, t2), tref, \n",
    "                               dt, upsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data parameters\n",
    "duration = 100000\n",
    "n_bins = int(duration / model_dt)\n",
    "n_frames = n_bins // upsample\n",
    "n_assim = 1\n",
    "n_test = 5\n",
    "\n",
    "# generate data to fit\n",
    "np.random.seed(1)\n",
    "mat.random_seed(1)\n",
    "data = []\n",
    "stim = np.random.randn(n_frames)\n",
    "stim[:100] = 0\n",
    "        \n",
    "V = filter_stimulus(stim, k1)\n",
    "for i in range(n_assim + n_test):\n",
    "    spikes = predict_spikes(V, matparams, model_dt, upsample)\n",
    "    H = mat.adaptation(spikes, matparams[3:5], model_dt)\n",
    "    z = np.nonzero(spikes)[0]\n",
    "    d = {\"H\": H,\n",
    "         \"duration\": duration,\n",
    "         \"spike_t\": z, \n",
    "         \"spike_v\": spikes,\n",
    "         \"loglike\": mat.log_likelihood_poisson(V - matparams[0], H, spikes, matparams[1:3], model_dt, upsample)\n",
    "        }\n",
    "    data.append(d)\n",
    "\n",
    "# split into assimilation and test sets\n",
    "assim_data = data[:n_assim]\n",
    "test_data = data[n_assim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(211)\n",
    "ax2 = plt.subplot(212)\n",
    "for i, d in enumerate(data):\n",
    "    ax2.vlines(d[\"spike_t\"], i, i + 0.5)\n",
    "ax1.plot(V)\n",
    "ax1.set_xlim(0, 8000 / upsample)\n",
    "ax2.set_xlim(0, 8000)\n",
    "print(\"log likelihood: {}\".format(np.sum([d[\"loglike\"] for d in data])))\n",
    "print(\"spikes: {}; rate: {} / dt\".format(np.mean([d[\"spike_t\"].size for d in data]), \n",
    "                                         np.mean([d[\"spike_t\"].size / d[\"duration\"] for d in data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial guess of parameters using cross-validated ML\n",
    "ntbas = 8\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "spike_v = np.stack([d[\"spike_v\"] for d in assim_data], axis=1)\n",
    "spike_h = np.stack([d[\"H\"] for d in assim_data], axis=2)\n",
    "mlest = mle.mat(stim, kcosbas, spike_v, spike_h, stim_dt, model_dt, nlin=\"softplus\")\n",
    "%time w0 = mlest.estimate(reg_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(w0[:3])\n",
    "rf_sta = strf.from_basis(mlest.sta(), kcosbas)\n",
    "rf_ml = strf.from_basis(w0[3:], kcosbas)\n",
    "plt.plot(k1)\n",
    "plt.plot(rf_sta)\n",
    "plt.plot(rf_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimate parameters using emcee\n",
    "from neurofit import priors, costs, utils, startpos\n",
    "import emcee\n",
    "\n",
    "# assimilation parameters\n",
    "if sys.platform == 'darwin':\n",
    "    nthreads = 1\n",
    "else:\n",
    "    nthreads = 8\n",
    "nwalkers = 500\n",
    "nsteps = 500\n",
    "\n",
    "mat_prior = priors.joint_independent(\n",
    "                [ priors.uniform( 0,  20),\n",
    "                  priors.uniform(-50,  200),\n",
    "                  priors.uniform(-5,   10),\n",
    "                ])\n",
    "\n",
    "# lasso prior on RF parameters\n",
    "rf_lambda = 1.0\n",
    "\n",
    "def matbounds(t1, t2, tr):\n",
    "    aa1 = -(1 - np.exp(-tr/t2))/(1 - np.exp(-tr/t1))\n",
    "    aa2 = -(np.exp(tr/t2) - 1)/(np.exp(tr/t1) - 1)\n",
    "    def f(mparams):\n",
    "        return (mparams[2] > aa1 * mparams[1]) and (mparams[2] > aa2 * mparams[1])\n",
    "    return f\n",
    "\n",
    "matboundprior = matbounds(*matparams[3:6])\n",
    "\n",
    "def lnprior(theta):\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    if not matboundprior(mparams):\n",
    "        return -np.inf\n",
    "    rf_prior = -np.sum(np.abs(rfparams)) * rf_lambda\n",
    "    ll = mat_prior(mparams) + rf_prior\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return ll\n",
    "\n",
    "\n",
    "def loglike_poisson(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    return mu[spike_t].sum() - np.exp(mu).sum() * dt \n",
    "\n",
    "\n",
    "def loglike_sigmoid(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    lmb = (1 + np.tanh(mu / 2)) / 2\n",
    "    return np.log(lmb[spike_t]).sum() - lmb.sum() * dt \n",
    "\n",
    "\n",
    "def loglike_softplus(V, H, spike_t, alpha, dt):\n",
    "    mu = V - np.dot(H, alpha)\n",
    "    lmb = np.log1p(np.exp(mu))\n",
    "    return np.log(lmb[spike_t]).sum() - lmb.sum() * dt \n",
    "    \n",
    "    \n",
    "def lnlike(theta):\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    Vi = mlest.V_interp(theta).squeeze() - mparams[0]\n",
    "    lp = 0\n",
    "    for d in assim_data:\n",
    "        lp += loglike_softplus(Vi, d[\"H\"], d[\"spike_t\"], mparams[1:3], model_dt)\n",
    "    return lp   \n",
    "\n",
    "def lnpost_dyn(theta):\n",
    "    \"\"\"Posterior probability for dynamical parameters\"\"\"\n",
    "    return lnprior(theta) - mlest.loglike(theta) #+ lnlike(theta) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# theoretically this is as good as it can get\n",
    "theta_true = np.concatenate([matparams_f, k1c])\n",
    "print(\"lnpost of p_true: {}\".format(lnpost_dyn(theta_true)))\n",
    "# initial state is a gaussian ball around the ML estimate\n",
    "p0 = startpos.normal_independent(nwalkers, w0, np.abs(w0) * 2)\n",
    "theta_0 = np.median(p0, 0)\n",
    "print(\"lnpost of p0 median: {}\".format(lnpost_dyn(theta_0)))\n",
    "%timeit lnpost_dyn(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, theta_true.size, lnpost_dyn, threads=nthreads)\n",
    "tracker = utils.convergence_tracker(nsteps, 25)\n",
    "\n",
    "for pos, prob, _ in tracker(sampler.sample(p0, iterations=nsteps, storechain=False)): \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"lnpost of p median: {}\".format(np.median(prob)))\n",
    "print(\"average acceptance fraction: {}\".format(sampler.acceptance_fraction.mean()))\n",
    "theta = np.median(pos, 0)\n",
    "mparams = theta[:matparams_n]\n",
    "rfparams = theta[matparams_n:]\n",
    "plt.plot(k1)\n",
    "plt.plot(strf.from_basis(rfparams, kcosbas))\n",
    "print(matparams_f)\n",
    "print(w0[:3])\n",
    "print(theta[:matparams_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mpos = pos[:,:matparams_n]\n",
    "matlabs = ['a1','a2','w']\n",
    "c = corner(mpos,\n",
    "           #range=[sp for sp in startparams],\n",
    "       bins=50, smooth=2,smooth1d=0,\n",
    "       labels=matlabs,\n",
    "       truths=matparams_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see how well predictions line up\n",
    "d = assim_data[0]\n",
    "Vpred = mlest.V(theta)\n",
    "\n",
    "plt.plot(V[:400])\n",
    "plt.plot(Vpred[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# posterior predictive distribution\n",
    "for j, d in enumerate(test_data):\n",
    "    plt.vlines(d[\"spike_t\"], j, j + 0.5, 'r')\n",
    "\n",
    "mparamp = matparams.copy()\n",
    "samples = np.random.permutation(nwalkers)[:n_test]\n",
    "for i, idx in enumerate(samples):\n",
    "    sample = pos[idx]\n",
    "    V = mlest.V(sample)\n",
    "    mparamp[matparams_i] = sample[:matparams_n]\n",
    "    S = predict_spikes(V, mparamp, model_dt, upsample)\n",
    "    spk_t = S.nonzero()[0]\n",
    "    plt.vlines(spk_t, i + j + 1, i + j + 1.5)\n",
    "\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
