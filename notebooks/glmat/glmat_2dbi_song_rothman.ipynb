{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLMAT: 2D kernel, song stimuli, biophysical model, ML+MC estimation\n",
    "\n",
    "This notebook tests the full estimation method on data generated by a biophysical dSTRF model. The goal ois to estimate the parameters of the RF and the adaptation kernels. The parameter count of the RF is minimized by using a low-rank approximation (i.e., an outer product of two vectors) and by projecting time into a basis set of raised cosine filters that are spaced exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "from dstrf import strf, mle, io, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.aspect'] = 'auto'\n",
    "mpl.rcParams['image.cmap'] = 'jet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAT model is governed by a small number of parameters: the spike threshold (omega), the amplitudes of the adaptation kernels (alpha_1, alpha_2), the time constants of the adaptation kernels (tau_1, tau_2), and the absolute refactory period. In addition, a function must be chosen for the probability of spike generation. The 'softplus' function, log(1 + exp(mu)), is a good choice because it doesn't saturate as readily when mu is large. Because there can only be one spike per bin, saturation causes the estimated parameters to be less than the true parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model time step\n",
    "model_dt = 0.5\n",
    "\n",
    "# spectrogram parameters\n",
    "stim_dt = 3.0\n",
    "upsample = int(stim_dt / model_dt)\n",
    "spec_window = 2.5\n",
    "spec_compress = 10\n",
    "f_min = 0.0\n",
    "f_max = 8.0\n",
    "\n",
    "# strf parameters\n",
    "nfreq = 20\n",
    "ntau  = 30\n",
    "# these parameters influence how the STRF dimensional reduction will work\n",
    "ntbas = 10       # number of temporal basis functions\n",
    "krank = 2        # rank of bilinear approximation\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "ntbas = kcosbas.shape[1]\n",
    "\n",
    "# time constants for the spike history kernels\n",
    "htau = np.asarray([10, 200], dtype='d')\n",
    "# nonlinearity used to calculate likelihood\n",
    "nlin = \"softplus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load data from the dSTRF experiments. Each RF was convolved with 30 different songs, then the linear output was fed into the biophysical equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data parameters - the number of trials for assimilation and for testing\n",
    "pad_before = 0    # how much to pad stimulus before onset\n",
    "pad_after = ntau * stim_dt # how much to pad after offset\n",
    "n_trials = 10      # set the number of trials to use (needs to be the same for all stimuli)\n",
    "p_test = 0.5      # proportion of trials to use for test\n",
    "\n",
    "# song stimulus:\n",
    "root = \"/scratch/dmeliza/modeldata/SNR4posp-norm/\"\n",
    "cell = \"b-tonic-24\"\n",
    "data = io.load_rothman(cell, root, spec_window, stim_dt, f_min=f_min, f_max=f_max, f_count=nfreq, \n",
    "                       compress=spec_compress, gammatone=False)\n",
    "\n",
    "io.pad_stimuli(data, pad_before, pad_after, fill_value=0.0);\n",
    "io.preprocess_spikes(data, model_dt, htau)\n",
    "\n",
    "n_test = int(p_test * len(data))\n",
    "# split into assimilation and test sets and merge stimuli\n",
    "assim_data = io.merge_data(data[:-n_test])\n",
    "test_data = io.merge_data(data[-n_test:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stim = assim_data[\"stim\"]\n",
    "plt.subplot(311).imshow(assim_data[\"stim\"], extent=(0, assim_data[\"duration\"], f_min, f_max))\n",
    "t_spike = np.linspace(0, assim_data[\"duration\"], assim_data[\"spike_v\"].shape[0])\n",
    "plt.subplot(312).plot(t_spike, assim_data[\"spike_v\"].sum(1))\n",
    "ax = plt.subplot(313)\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    ax.vlines(spk * model_dt, i, i + 0.5)\n",
    "    ax.plot(t_spike, assim_data[\"spike_h\"][:, :, i])\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "The reg_alpha and reg_lambda parameters set the L1 and L2 penalties for the initial ML estimation. Note that we supply the nonlinearity function to the constructor too, as this determines how the log-likelihood is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial guess of parameters using penalized ML. Note that we provide the cosine basis set to the constructor of\n",
    "# mle.estimator, which causes the design matrix to be in the cosine basis set\n",
    "mlest = mle.mat(assim_data[\"stim\"], kcosbas, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                assim_data[\"stim_dt\"], assim_data[\"spike_dt\"], nlin=nlin)\n",
    "# also construct an estimator for the test object so we can score results\n",
    "mltest = mle.mat(test_data[\"stim\"], kcosbas, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                       test_data[\"stim_dt\"], test_data[\"spike_dt\"], nlin=nlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# low-rank estimators\n",
    "mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                assim_data[\"stim_dt\"], assim_data[\"spike_dt\"], nlin=nlin)\n",
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                       test_data[\"stim_dt\"], test_data[\"spike_dt\"], nlin=nlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_alpha = 1e1\n",
    "rf_lambda = 1e1\n",
    "%time w0 = mlest.estimate(reg_lambda=rf_lambda, reg_alpha=rf_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(w0[:3])\n",
    "# the RF is in the cosine basis set, which we need to convert back in order to visualize\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "#rf_mle = strf.as_matrix(w0[3:], kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], nfreq, krank), kcosbas)\n",
    "\n",
    "rf_true = np.fliplr(io.load_rothman_rf(cell, root))\n",
    "from scipy.signal import resample\n",
    "# pad RF out to ntau\n",
    "# if rf_true.shape[1] < ntau * stim_dt:\n",
    "#     rf_true = np.column_stack([np.zeros((rf_true.shape[0], int(stim_dt * ntau) - rf_true.shape[1])), rf_true])\n",
    "rsmpl_rf = np.fliplr(resample(resample(rf_true,20),40,axis=1))\n",
    "rsmpl_rf = np.vstack((np.zeros((3,40)), rsmpl_rf[:-3,:]))\n",
    "rsmpl_rf = np.hstack((np.zeros((20,3)), rsmpl_rf[:,:-3]))\n",
    "\n",
    "plt.subplot(421).imshow(rf_true)\n",
    "plt.title(\"STA\")\n",
    "plt.subplot(422).imshow(rf_mle)\n",
    "plt.title(\"ML estimate\")\n",
    "plt.subplot(424).imshow(rf_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from dstrf import crossvalidate\n",
    "\n",
    "#reg_grid = np.logspace(-1, 5, 50)[::-1]\n",
    "l1_ratios = [0.1, 0.5, 0.7, 0.9, 0.95]\n",
    "reg_grid = np.logspace(-1, 5, 20)[::-1]\n",
    "scores = []\n",
    "results = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(l1_ratios) * len(reg_grid),\n",
    "                              widgets=[\n",
    "                                ' [', progressbar.Timer(), '] ',\n",
    "                                progressbar.Bar(),\n",
    "                                ' (', progressbar.ETA(), ') ',\n",
    "                            ])\n",
    "for reg, s, w in bar(crossvalidate.elasticnet(mlest, 4, reg_grid, l1_ratios, avextol=1e-5, disp=False)):\n",
    "    scores.append(s)\n",
    "    results.append((reg, s, w))\n",
    "    \n",
    "best_idx = np.argmax(scores)\n",
    "best = results[best_idx]\n",
    "print(\"best solution at {}: {}\".format(best[0], best[1]))\n",
    "rf_alpha, rf_lambda = best[0]\n",
    "w0 = best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"best solution at {}: {}\".format(best[0], best[1]))\n",
    "print(w0[:3])\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], nfreq, krank), kcosbas)\n",
    "plt.subplot(422).imshow(rf_mle[:,-13:])\n",
    "plt.title(\"ML estimate\")\n",
    "plt.subplot(424).imshow(rf_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat.random_seed(1)\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "plt.subplot(311).imshow(test_data[\"stim\"], extent=(0, test_data[\"duration\"], f_min, f_max))\n",
    "V = mltest.V(w0)\n",
    "plt.subplot(312).plot(t_stim, V)\n",
    "ax = plt.subplot(313)\n",
    "for j, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    ax.vlines(spk * model_dt, j, j + 0.5, 'r')\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for i in range(j):\n",
    "    pred[:, i] = mltest.predict(w0, matparams[3:], V)\n",
    "    spk_t = pred[:, i].nonzero()[0]\n",
    "    ax.vlines(spk_t * model_dt, i + j + 1, i + j + 1.5)\n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "ax.plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 4200)\n",
    "\n",
    "#eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"loglike: {}\".format(-mltest.loglike(w0)))\n",
    "#print(\"CC: {}/{}\".format(np.corrcoef(test_psth, pred_psth)[0, 1], eo))\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the ML estimate to seed the MCMC sampler. We're going to reduce the size of the parameter space by factorizing the RF (i.e., a bilinear approximation). Note that we try to use the mlest object as much as possible to do the calculations rather than reimplement things; however, there can be some significant performance enhancements from an optimized implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate parameters using emcee\n",
    "from neurofit import priors, costs, utils, startpos\n",
    "\n",
    "# the MAT parameters are just bounded between reasonable limits. These may need to be expanded when using real data.\n",
    "mat_prior = priors.joint_independent(\n",
    "                [ priors.uniform( 0,  20),\n",
    "                  priors.uniform(-50,  200),\n",
    "                  priors.uniform(-5,   10),\n",
    "                ])\n",
    "\n",
    "def lnpost(theta):\n",
    "    \"\"\"Posterior probability for dynamical parameters\"\"\"\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    #rf_prior = -np.sum(np.abs(rfparams)) * rf_alpha - np.dot(rfparams, rfparams) * rf_lambda\n",
    "    ll = mat_prior(mparams) #+ rf_prior\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    w = np.r_[mparams, rfparams]\n",
    "    ll -= mlest.loglike(w, rf_lambda, rf_alpha)\n",
    "    return -np.inf if not np.isfinite(ll) else ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get low-rank approx of the ML STRF\n",
    "# k0f, k0t = strf.factorize(strf.as_matrix(w0[3:], ntbas))\n",
    "# rf_mlb = strf.from_basis(np.dot(k0f, k0t), kcosbas)\n",
    "# w0_bl = np.r_[w0[:3], k0f.squeeze(), k0t.squeeze()]\n",
    "print(\"lnpost of ML estimate: {}\".format(lnpost(w0)))\n",
    "%timeit lnpost(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code starts the MCMC sampler. We initialize the walkers (chains) in a gaussian around the ML estimate, with standard deviation 2x the absolute value of the best guess. The model converges fairly quickly, but then we let it sample for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import emcee\n",
    "# assimilation parameters\n",
    "if sys.platform == 'darwin':\n",
    "    nthreads = 1\n",
    "else:\n",
    "    nthreads = 8\n",
    "nwalkers = 500\n",
    "nsteps = 500\n",
    "\n",
    "# initialize walkers\n",
    "pos = p0 = startpos.normal_independent(nwalkers, w0, np.abs(w0) * 2)\n",
    "# initialize the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, w0.size, lnpost, threads=nthreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start the sampler\n",
    "tracker = utils.convergence_tracker(nsteps, 100)\n",
    "for pos, prob, like in tracker(sampler.sample(pos, iterations=nsteps, storechain=True)): \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"lnpost of p median: {}\".format(np.median(prob)))\n",
    "print(\"average acceptance fraction: {}\".format(sampler.acceptance_fraction.mean()))\n",
    "try:\n",
    "    print(\"autocorrelation time: {}\".format(sampler.acor))\n",
    "except:\n",
    "    pass    \n",
    "w1 = np.median(pos, 0)\n",
    "rfparams = w1[3:]\n",
    "rf_map = strf.from_basis(strf.defactorize(rfparams, nfreq, krank), kcosbas)\n",
    "print(w0[:matparams_n])\n",
    "print(w1[:matparams_n])\n",
    "# print(\"mle error: {}; map error: {}\".format(strf.subspace(k1, rf_mle), strf.subspace(k1, rf_map)))\n",
    "#plt.subplot(221)\n",
    "#sns.heatmap(strf.from_basis(k1c, kcosbas), cmap='jet')\n",
    "plt.subplot(222)\n",
    "sns.heatmap(rf_mle[:,-13:], cmap='jet')\n",
    "plt.subplot(224)\n",
    "sns.heatmap(rf_map[:,-13:], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mpos = pos[:,:matparams_n]\n",
    "matlabs = ['w','a1','a2',]\n",
    "c = corner(mpos,\n",
    "       bins=50, smooth=2,smooth1d=0,\n",
    "       labels=matlabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat.random_seed(1)\n",
    "n_draw = 10\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "plt.subplot(311).imshow(test_data[\"stim\"], extent=(0, test_data[\"duration\"], f_min, f_max))\n",
    "vax = plt.subplot(312)\n",
    "ax = plt.subplot(313)\n",
    "for j, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    ax.vlines(spk * model_dt, j, j + 0.5, 'r')\n",
    "    \n",
    "samples = np.random.permutation(nwalkers)[:n_draw]\n",
    "pred = np.zeros((test_data[\"spike_v\"].shape[0], n_draw), dtype=test_data[\"spike_v\"].dtype)\n",
    "for i, idx in enumerate(samples):\n",
    "    mparams = pos[idx]\n",
    "    V_mc = mltest.V(mparams)\n",
    "    vax.plot(t_stim, V_mc)\n",
    "    pred[:, i] = mltest.predict(mparams, matparams[3:], V_mc)\n",
    "    spk_t = pred[:, i].nonzero()[0]\n",
    "    ax.vlines(spk_t * model_dt, i + j + 1, i + j + 1.5)\n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "ax.plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 4200)\n",
    "\n",
    "#eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"loglike: {}\".format(-mltest.loglike(w1)))\n",
    "#print(\"CC: {}/{}\".format(np.corrcoef(test_psth, pred_psth)[0, 1], eo))\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum() / n_trials, pred.sum() / n_draw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(4,6))\n",
    "stim = test_data[\"stim\"]\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "#t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"I\"].shape[0])\n",
    "\n",
    "plt.subplot(511).imshow(test_data[\"stim\"], extent=(0, test_data[\"duration\"], f_min, f_max))\n",
    "\n",
    "plt.subplot(512).vlines(test_data[\"spike_t\"][5] * model_dt, -0.4, 0.4)\n",
    "# for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "#     ax.vlines(spk * model_dt, i, i + 0.5)\n",
    "plt.subplot(513).plot(t_stim, V_mc)\n",
    "H = -test_data[\"spike_h\"][:, :, 5]\n",
    "plt.subplot(514).plot(t_spike, H)\n",
    "lci = mltest.lci(w1)\n",
    "plt.subplot(515).plot(t_spike, np.exp(lci[:, 5]))\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(19760,21800)\n",
    "plt.savefig(\"glm_fit_example_{}.pdf\".format(cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save data for testing in the Pillow code\n",
    "import scipy.io as sio\n",
    "V = mlest.V_interp(theta_true).squeeze()\n",
    "H = assim_resp[0][\"H\"]\n",
    "mu = V - H[:, 0] * matparams[1] - H[:, 1] * matparams[2] - matparams[0]\n",
    "sio.savemat('glmat_2dbi_song_twin.mat', {\"stim\": (stim - stim.mean(1)[:, np.newaxis]) / stim.std(1)[:, np.newaxis], \n",
    "                                         \"spikes\": assim_resp[0][\"spike_v\"],\n",
    "                                         \"stim_dt\": stim_dt,\n",
    "                                         \"spike_dt\": model_dt,\n",
    "                                         \"rf\": k1,\n",
    "                                         \"Istim\": V,\n",
    "                                         \"Itot\": mu})"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
