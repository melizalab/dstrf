{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLMAT: 2D kernel (low-rank), ML+MC estimation \u2014 song stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "import mat_neuron._model as mat\n",
    "from dstrf import strf, mle, io\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters: (\u03c9, \u03b11, \u03b12, \u03c41, \u03c42, tref)\n",
    "matparams = np.asarray([7, 100, 2, 10, 200, 2], dtype='d')\n",
    "model_dt = 0.5\n",
    "\n",
    "matparams_i = [0,1,2]\n",
    "matparams_n = len(matparams_i)\n",
    "matparams_f = matparams[matparams_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRF: keep this very simple for proof of principle\n",
    "stim_dt = 3.0\n",
    "upsample = int(stim_dt / model_dt)\n",
    "kscale = 8\n",
    "f_min = 0.25\n",
    "f_max = 8.0\n",
    "nfreq = 20\n",
    "ntau  = 40\n",
    "ntbas = 8\n",
    "\n",
    "# raised-cosine basis functions\n",
    "kcosbas = strf.cosbasis(ntau, ntbas)\n",
    "ntbas = kcosbas.shape[1]\n",
    "\n",
    "from scipy.signal import resample\n",
    "filts = np.load('../../filters.npz')\n",
    "print(filts.keys())\n",
    "k1 = resample(filts['bbs'] * kscale, nfreq, axis=0)[:,ntau-1::-1]\n",
    "\n",
    "sns.heatmap(k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "n_test = 5\n",
    "n_trials = 3\n",
    "\n",
    "# song stimulus:\n",
    "root = os.path.join(os.environ[\"HOME\"], \"data\", \"crcns\")\n",
    "cell = \"yg0616_4_B\"\n",
    "stim_type = \"conspecific\"\n",
    "data = io.load_crcns(cell, stim_type, root, 4.0, stim_dt, f_min=f_min, f_max=f_max, f_count=nfreq, compress=1, gammatone=True)\n",
    "# split into assimilation and test sets and merge stimuli\n",
    "assim_data = io.merge_data(data[:-n_test], pad_before=1000, pad_after=1000, dt=stim_dt)\n",
    "test_data = io.merge_data(data[n_test:], pad_before=1000, pad_after=1000, dt=stim_dt)\n",
    "plt.subplot(211).imshow(assim_data['stim'], cmap='jet', aspect='auto', extent=(0, assim_data[\"duration\"], f_min, f_max))\n",
    "ax = plt.subplot(212)\n",
    "for i, d in enumerate(assim_data[\"spikes\"]):\n",
    "    ax.vlines(d, i, i + 0.5)\n",
    "ax.set_xlim(0, assim_data[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.random_seed(1)\n",
    "\n",
    "def predict_spikes(V, params, dt, upsample):\n",
    "    omega, a1, a2, t1, t2, tref = params\n",
    "    return mat.predict_poisson(V - omega, (a1, a2), (t1, t2), tref, \n",
    "                               dt, upsample)\n",
    "\n",
    "stim = assim_data[\"stim\"]\n",
    "V = strf.convolve(stim, k1)\n",
    "assim_resp = [] \n",
    "for i in range(n_trials):\n",
    "    spikes = predict_spikes(V, matparams, model_dt, upsample)\n",
    "    H = mat.adaptation(spikes, matparams[3:5], model_dt)\n",
    "    z = np.nonzero(spikes)[0]\n",
    "    d = dict(H=H,\n",
    "             spike_t=z,\n",
    "             spike_v=spikes)\n",
    "    assim_resp.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(311).imshow(stim, cmap='jet', aspect='auto', extent=(0, assim_data[\"duration\"], f_min, f_max))\n",
    "plt.subplot(312).plot(np.linspace(0, assim_data[\"duration\"], V.size), V)\n",
    "ax = plt.subplot(313)\n",
    "for i, d in enumerate(assim_resp):\n",
    "    ax.vlines(d[\"spike_t\"] * model_dt, i, i + 0.5)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess of parameters using ML\n",
    "spikes = np.stack([d[\"spike_v\"] for d in assim_resp], axis=1)\n",
    "mlest = mle.estimator(stim, spikes, kcosbas, matparams[3:5], stim_dt, model_dt)\n",
    "%time w0 = mlest.estimate(maxiter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w0[:3])\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.as_matrix(w0[3:], kcosbas)\n",
    "plt.subplot(221).imshow(k1, cmap='jet', aspect='auto')\n",
    "plt.subplot(222).imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "plt.subplot(223).imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "plt.subplot(224).imshow(rf_mle, cmap='jet', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate parameters using emcee\n",
    "from neurofit import priors, costs, utils, startpos\n",
    "import emcee\n",
    "\n",
    "# assimilation parameters\n",
    "if sys.platform == 'darwin':\n",
    "    nthreads = 1\n",
    "else:\n",
    "    nthreads = 8\n",
    "nwalkers = 1000\n",
    "nsteps = 200\n",
    "\n",
    "mat_prior = priors.joint_independent(\n",
    "                [ priors.uniform( 0,  20),\n",
    "                  priors.uniform(-50,  200),\n",
    "                  priors.uniform(-5,   10),\n",
    "                ])\n",
    "\n",
    "# lasso prior on RF parameters\n",
    "rf_lambda = 1.0\n",
    "X_stim = mlest._X_stim.get_value()\n",
    "\n",
    "def lnpost_dyn(theta):\n",
    "    \"\"\"Posterior probability for dynamical parameters\"\"\"\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    rf_prior = -np.sum(np.abs(rfparams)) * rf_lambda\n",
    "    ll = mat_prior(mparams) + rf_prior\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    lp = 0\n",
    "    # reassemble strf\n",
    "    kf = rfparams[:nfreq]\n",
    "    kt = rfparams[nfreq:]\n",
    "    k = np.outer(kf, kt).flatten()    \n",
    "    V = np.dot(X_stim, k)\n",
    "    # the log_likelihood method in mat-neuron will abort if the likelihood blows up, so it's a bit faster at converging.\n",
    "    for d in assim_resp:\n",
    "        lp += mat.log_likelihood_poisson(V - mparams[0], d[\"H\"], d[\"spike_v\"], mparams[1:3], model_dt, upsample)\n",
    "    return ll + lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get low-rank approx of the ML STRF\n",
    "k0f, k0t = strf.factorize(strf.as_matrix(w0[3:], ntbas))\n",
    "rf_mlb = strf.from_basis(np.dot(k0f, k0t), kcosbas)\n",
    "w0_bl = np.r_[w0[:3], k0f.squeeze(), k0t.squeeze()]\n",
    "print(\"lnpost of ML estimate: {}\".format(lnpost_dyn(w0_bl)))\n",
    "\n",
    "# and this is our initial population of walkers\n",
    "pos = p0 = startpos.normal_independent(nwalkers, w0_bl, np.abs(w0_bl) * 0.2)\n",
    "theta_0 = np.median(p0, 0)\n",
    "print(\"lnpost of p0 median: {}\".format(lnpost_dyn(theta_0)))\n",
    "%timeit lnpost_dyn(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, theta_0.size, lnpost_dyn, threads=nthreads)\n",
    "tracker = utils.convergence_tracker(nsteps, 1)\n",
    "\n",
    "for pos, prob, _ in tracker(sampler.sample(pos, iterations=nsteps, storechain=True)): \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lnpost of p median: {}\".format(np.median(prob)))\n",
    "print(\"average acceptance fraction: {}\".format(sampler.acceptance_fraction.mean()))\n",
    "w1 = np.median(pos, 0)\n",
    "rfparams = w1[3:]\n",
    "kf = rfparams[:nfreq]\n",
    "kt = rfparams[nfreq:]\n",
    "rf_map = strf.from_basis(np.outer(kf, kt), kcosbas)\n",
    "print(w0[:matparams_n])\n",
    "print(w1[:matparams_n])\n",
    "print(\"mle error: {}; map error: {}\".format(strf.subspace(k1, rf_mle), strf.subspace(k1, rf_map)))\n",
    "plt.subplot(221).imshow(k1, cmap='jet', aspect='auto')\n",
    "plt.subplot(222).imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "plt.subplot(223).imshow(rf_mlb, cmap='jet', aspect='auto')\n",
    "plt.subplot(224).imshow(rf_map, cmap='jet', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mpos = pos[:,:matparams_n]\n",
    "matlabs = ['w','a1','a2',]\n",
    "c = corner(mpos,\n",
    "       bins=50, smooth=2,smooth1d=0,\n",
    "       labels=matlabs,\n",
    "       truths=theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how well predictions line up\n",
    "Vref = mlest.V(theta_true)\n",
    "V_ml = mlest.V(w0)\n",
    "V_map = strf.convolve(stim, rf_map)\n",
    "\n",
    "plt.plot(Vref)\n",
    "plt.plot(V_ml)\n",
    "plt.plot(V_map)\n",
    "plt.xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive distribution\n",
    "stim = test_data[\"stim\"]\n",
    "V = strf.convolve(stim, k1)\n",
    "assim_resp = [] \n",
    "for j in range(n_trials):\n",
    "    spikes = predict_spikes(V, matparams, model_dt, upsample)\n",
    "    z = np.nonzero(spikes)[0]\n",
    "    plt.vlines(z, j, j + 0.5, 'r')\n",
    "\n",
    "ndraw = 10\n",
    "mparams = matparams.copy()\n",
    "samples = np.random.permutation(nwalkers)[:ndraw]\n",
    "mparams[matparams_i] = w1[:matparams_n]\n",
    "V = strf.convolve(stim, rf_map)\n",
    "for i, idx in enumerate(samples):\n",
    "    mparams[matparams_i] = pos[idx, :matparams_n]\n",
    "    S = predict_spikes(V, mparams, model_dt, upsample)\n",
    "    spk_t = S.nonzero()[0]\n",
    "    plt.vlines(spk_t, i + j + 1, i + j + 1.5)\n",
    "\n",
    "plt.xlim(0, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "dstrf",
   "language": "python",
   "name": "dstrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}