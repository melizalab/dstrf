{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM Demo: multivariate song stimulus\n",
    "\n",
    "This demo estimates GLM parameters using song stimuli. The song waveform is processed to a 2D spectrogram, then convolved with a 2D STRF to produce the \"voltage\" of the GLM model. The adaptation \"current\" is calculated by convolving the spike trains with two exponential kernels. The goal of the assimilation is to estimate the parameters of the RF and the adaptation kernels. The parameter count of the RF is minimized by using a low-rank approximation (i.e., an outer product of two vectors) and by projecting time into a basis set of raised cosine filters that are spaced exponentially.\n",
    "\n",
    "This notebook also demonstrates the use of elastic-net penalized maximum-likelihood estimation to regularize parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import imp\n",
    "import numpy as np\n",
    "\n",
    "from dstrf import strf, mle, simulate, filters, models, io, spikes, performance\n",
    "\n",
    "# plotting packages\n",
    "%reload_ext yamlmagic\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.aspect'] = 'auto'\n",
    "mpl.rcParams['image.cmap'] = 'jet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cfg\n",
    "model:\n",
    "  dt: 0.5\n",
    "  ataus: [10.0, 200.0]\n",
    "  t_refract: 2.0\n",
    "  filter:\n",
    "    rank: 2\n",
    "    len: 40\n",
    "    ncos: 12\n",
    "data:\n",
    "  dt: 3.0\n",
    "  spectrogram:\n",
    "    window: 4.0\n",
    "    compress: 10\n",
    "    f_min: 1000\n",
    "    f_max: 8000\n",
    "  filter:\n",
    "    fn: \"gabor\"\n",
    "    nfreq: 20\n",
    "    ntau: 40\n",
    "    f_max: 8000\n",
    "    f_peak: 4000\n",
    "    t_peak: 12\n",
    "    ampl: -1\n",
    "    t_sigma: 6\n",
    "    f_sigma: 2400\n",
    "    theta: 0\n",
    "    lmbda: 19\n",
    "    psi: 1.5\n",
    "  adaptation: [7.0, 100.0, 2.0]\n",
    "  trial_noise:\n",
    "    sd: 2.0\n",
    "  random_seed: 1\n",
    "  trials: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munch import munchify\n",
    "cf = munchify(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = cf.model.dt\n",
    "stim_dt = cf.data.dt\n",
    "upsample = int(stim_dt / model_dt)\n",
    "ntau = cf.model.filter.len\n",
    "nfreq = cf.data.filter.nfreq\n",
    "ncos = cf.model.filter.ncos\n",
    "krank = cf.model.filter.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates the simulated response. First we convolve the stimulus with the RF and then use the MAT model to generate spikes from a non-homogeneous Poisson process (optionally using a softplus nonlinearity, which makes the model not-quite-Poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, _, _ = filters.gabor(**cf.data.filter)\n",
    "kcosbas = strf.cosbasis(ntau, ncos)\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "k1f, k1t = strf.factorize(k1c, rank=krank)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(4, 6))\n",
    "axes[0].imshow(k1, cmap=\"jet\", aspect=\"auto\")\n",
    "axes[0].set_title(\"True RF\")\n",
    "axes[1].imshow(strf.from_basis(k1c, kcosbas), cmap=\"jet\", aspect=\"auto\")\n",
    "axes[1].set_title(\"cosine approximation\")\n",
    "k1v = np.concatenate([k1f.flatten(), k1t.flatten()])\n",
    "axes[2].imshow(strf.from_basis(strf.defactorize(k1v, nfreq, krank), kcosbas), cmap='jet')\n",
    "axes[2].set_title(\"rank-{} approximation\".format(krank));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load some data from a real neural recording from the CRCNS dataset. We're going to replace the actual neural response with a simulation based on the dstrf model. In the original experiment, stimuli were presented individually in a pseudorandom order. To simplify the model, we concatenate the stimuli, setting padding between the stimuli sufficient to capture any offset responses.\n",
    "\n",
    "The method of concatenation is a bit clumsy, because we don't know what was \"presented\" during the silent gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_before = 0    # how much to pad stimulus before onset\n",
    "pad_after = ntau * stim_dt # how much to pad after offset\n",
    "n_trials = 5      # set the number of trials to use (needs to be the same for all stimuli)\n",
    "p_test = 0.2      # proportion of trials to use for test\n",
    "\n",
    "# song stimulus:\n",
    "root = os.path.join(os.environ[\"HOME\"], \"data\", \"crcns\")\n",
    "cell = \"blabla0903_2_B\"\n",
    "stim_type = \"conspecific\"\n",
    "data = io.load_crcns(cell, stim_type, root, cf.data.spectrogram.window, stim_dt, \n",
    "                     f_min=cf.data.spectrogram.f_min / 1000, \n",
    "                     f_max=cf.data.spectrogram.f_max / 1000, \n",
    "                     f_count=nfreq, \n",
    "                     compress=cf.data.spectrogram.compress, \n",
    "                     gammatone=True)\n",
    "io.pad_stimuli(data, pad_before, pad_after, fill_value=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat_neuron._model as mat\n",
    "mat.random_seed(1)\n",
    "\n",
    "def predict_spikes(V, dt, upsample):\n",
    "    omega, a1, a2 = cf.data.adaptation\n",
    "    t1, t2 = cf.model.ataus\n",
    "    tref = cf.model.t_refract\n",
    "    if nlin == \"exp\":\n",
    "        f = mat.predict_poisson\n",
    "    elif nlin == \"softplus\":\n",
    "        f = mat.predict_softplus\n",
    "    return f(V - omega, (a1, a2), (t1, t2), tref, dt, upsample)\n",
    "\n",
    "for d in data:\n",
    "    nchan, nframes = d[\"stim\"].shape\n",
    "    nbins = nframes * upsample\n",
    "    spike_v = np.zeros((nbins, n_trials), dtype='i')\n",
    "    spike_h = np.zeros((nbins, len(cf.model.ataus), n_trials), dtype='d')\n",
    "    V = strf.convolve(d[\"stim\"], k1)\n",
    "    spike_t = []\n",
    "    for i in range(n_trials):\n",
    "        spike_v[:, i] = models.predict_spikes_glm(V, cf.data.adaptation, cf)\n",
    "        spike_h[:, :, i] = mat.adaptation(spike_v[:, i], cf.model.ataus, model_dt)\n",
    "        spike_t.append(spike_v.nonzero()[0])\n",
    "    d[\"spike_v\"] = spike_v\n",
    "    d[\"spike_h\"] = spike_h\n",
    "    d[\"spike_t\"] = spike_t\n",
    "    d[\"spike_dt\"] = model_dt\n",
    "    \n",
    "n_test = int(p_test * len(data))\n",
    "# split into assimilation and test sets and merge stimuli\n",
    "assim_data = io.merge_data(data[:-n_test])\n",
    "test_data = io.merge_data(data[-n_test:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(311).imshow(assim_data[\"stim\"], \n",
    "                        extent=(0, assim_data[\"duration\"], \n",
    "                                cf.data.spectrogram.f_min, \n",
    "                                cf.data.spectrogram.f_max))\n",
    "t_stim = np.linspace(0, assim_data[\"duration\"], assim_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, assim_data[\"duration\"], assim_data[\"spike_v\"].shape[0])\n",
    "V = strf.convolve(assim_data[\"stim\"], k1)\n",
    "plt.subplot(312).plot(t_stim, V)\n",
    "ax = plt.subplot(313)\n",
    "for i, spk in enumerate(assim_data[\"spike_t\"]):\n",
    "    ax.vlines(spk * model_dt, i, i + 0.5)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate parameters\n",
    "\n",
    "Construct the factorized estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-rank estimators\n",
    "try:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])\n",
    "except TypeError:\n",
    "    mlest = mle.matfact(assim_data[\"stim\"], kcosbas, krank, assim_data[\"spike_v\"], assim_data[\"spike_h\"],\n",
    "                        assim_data[\"stim_dt\"], assim_data[\"spike_dt\"])    \n",
    "# also construct an estimator for the test data so we can score results\n",
    "mltest = mle.matfact(test_data[\"stim\"], kcosbas, krank, test_data[\"spike_v\"], test_data[\"spike_h\"],\n",
    "                     test_data[\"stim_dt\"], test_data[\"spike_dt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reg_alpha and reg_lambda parameters set the L1 and L2 penalties for the initial ML estimation. We'll start with some fairly moderate regularization just to get an initial estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time w0 = mlest.estimate(reg_lambda=1e1, reg_alpha=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to select regularization parameters using cross-validation. This makes use of the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from dstrf import crossvalidate\n",
    "\n",
    "#l1_ratios = [0.1, 0.5, 0.7, 0.9, 0.95]\n",
    "#reg_grid = np.logspace(-1, 5, 20)[::-1]\n",
    "l1_ratios = [0.5]\n",
    "reg_grid = [10, 1]\n",
    "scores = []\n",
    "results = []\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(l1_ratios) * len(reg_grid),\n",
    "                              widgets=[\n",
    "                                ' [', progressbar.Timer(), '] ',\n",
    "                                progressbar.Bar(),\n",
    "                                ' (', progressbar.ETA(), ') ',\n",
    "                            ])\n",
    "for reg, s, w in bar(crossvalidate.elasticnet(mlest, 4, reg_grid, l1_ratios, avextol=1e-5, disp=False)):\n",
    "    scores.append(s)\n",
    "    results.append((reg, s, w))\n",
    "    \n",
    "best_idx = np.argmax(scores)\n",
    "(rf_alpha, rf_lambda), ll, w0 = results[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True rate and adaptation parameters:\", cf.data.adaptation)\n",
    "print(\"best regularization params: alpha={}, lambda={}\".format(rf_alpha, rf_lambda))\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "k1c = strf.to_basis(k1, kcosbas)\n",
    "rf_sta = strf.as_matrix(mlest.sta(), kcosbas)\n",
    "rf_mle = strf.from_basis(strf.defactorize(w0[3:], nfreq, krank), kcosbas)\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_sta, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"STA\")\n",
    "axes[1, 1].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True)\n",
    "axes[0].imshow(test_data[\"stim\"], \n",
    "               extent=(0, test_data[\"duration\"], \n",
    "                                cf.data.spectrogram.f_min, \n",
    "                                cf.data.spectrogram.f_max))\n",
    "\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "t_spike = np.linspace(0, test_data[\"duration\"], test_data[\"spike_v\"].shape[0])\n",
    "V = strf.convolve(test_data[\"stim\"], k1)\n",
    "Vpred = mltest.V(w0)\n",
    "axes[1].plot(t_stim, V, t_stim, Vpred)\n",
    "\n",
    "n_trials = test_data[\"ntrials\"]\n",
    "for i, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    axes[2].vlines(spk * cf.model.dt, i - 0.4 + n_trials, i + 0.4 + n_trials)\n",
    "pred = np.zeros_like(test_data[\"spike_v\"])\n",
    "for j in range(n_trials):\n",
    "    pred[:, j] = models.predict_spikes_glm(Vpred, w0[:3], cf)\n",
    "    spk_t = pred[:, j].nonzero()[0]\n",
    "    axes[2].vlines(spk_t * cf.model.dt, j - 0.4, j + 0.4, color='r')\n",
    "\n",
    "upsample = int(cf.data.dt / cf.model.dt)   \n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "axes[3].plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "axes[3].set_xlim(0, 2000);\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"EO cc: %3.3f\" % eo)\n",
    "print(\"pred cc: %3.3f\" % np.corrcoef(test_psth, pred_psth)[0, 1])\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum(), pred.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the ML estimate to seed the MCMC sampler. We're going to reduce the size of the parameter space by factorizing the RF (i.e., a bilinear approximation). Note that we try to use the mlest object as much as possible to do the calculations rather than reimplement things; however, there can be some significant performance enhancements from an optimized implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate parameters using emcee\n",
    "from neurofit import priors, costs, utils, startpos\n",
    "\n",
    "# the MAT parameters are just bounded between reasonable limits. These may need to be expanded when using real data.\n",
    "mat_prior = priors.joint_independent(\n",
    "                [ priors.uniform( 0,  20),\n",
    "                  priors.uniform(-50,  200),\n",
    "                  priors.uniform(-5,   10),\n",
    "                ])\n",
    "\n",
    "rf_alpha, rf_lambda = best[0]\n",
    "\n",
    "def lnpost(theta):\n",
    "    \"\"\"Posterior probability for dynamical parameters\"\"\"\n",
    "    mparams = theta[:3]\n",
    "    rfparams = theta[3:]\n",
    "    #rf_prior = -np.sum(np.abs(rfparams)) * rf_alpha - np.dot(rfparams, rfparams) * rf_lambda\n",
    "    ll = mat_prior(mparams) #+ rf_prior\n",
    "    if not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    ll -= mlest.loglike(theta, rf_lambda, rf_alpha)\n",
    "    return -np.inf if not np.isfinite(ll) else ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lnpost of ML estimate: {}\".format(lnpost(w0)))\n",
    "%timeit lnpost(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code starts the MCMC sampler. We initialize the walkers (chains) in a gaussian around the ML estimate, with standard deviation 2x the absolute value of the best guess. The model converges fairly quickly, but then we let it sample for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "# assimilation parameters\n",
    "if sys.platform == 'darwin':\n",
    "    nthreads = 1\n",
    "else:\n",
    "    nthreads = 8\n",
    "nwalkers = 1500\n",
    "nsteps = 1000\n",
    "\n",
    "# initialize walkers\n",
    "pos = p0 = startpos.normal_independent(nwalkers, w0, np.abs(w0) * 2)\n",
    "# initialize the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, w0.size, lnpost, threads=nthreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the sampler\n",
    "tracker = utils.convergence_tracker(nsteps, 100)\n",
    "for pos, prob, like in tracker(sampler.sample(pos, iterations=nsteps, storechain=True)): \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.median(pos, 0)\n",
    "rfparams = w1[3:]\n",
    "rf_map = strf.from_basis(strf.defactorize(rfparams, nfreq, krank), kcosbas)\n",
    "\n",
    "print(\"lnpost of p median: {}\".format(np.median(prob)))\n",
    "print(\"average acceptance fraction: {}\".format(sampler.acceptance_fraction.mean()))\n",
    "print(\"True rate and adaptation parameters:\", matparams[:3])\n",
    "print(\"MLE rate and adaptation parameters:\", w0[:3])\n",
    "print(\"MAP rate and adaptation parameters:\", w1[:3])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(6, 6))\n",
    "\n",
    "axes[0, 0].imshow(k1, cmap='jet', aspect='auto')\n",
    "axes[0, 0].set_title(\"True RF\")\n",
    "axes[0, 1].imshow(strf.from_basis(k1c, kcosbas), cmap='jet', aspect='auto')\n",
    "axes[0, 1].set_title(\"RF from cosine basis\")\n",
    "axes[1, 0].imshow(rf_mle, cmap='jet', aspect='auto')\n",
    "axes[1, 0].set_title(\"MLE\")\n",
    "axes[1, 1].imshow(rf_map, cmap='jet', aspect='auto')\n",
    "axes[1, 1].set_title(\"MAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corner import corner\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "mpos = pos[:,:3]\n",
    "matlabs = ['w','a1','a2',]\n",
    "c = corner(mpos,\n",
    "       bins=50, smooth=2,smooth1d=0,\n",
    "       labels=matlabs,\n",
    "       truths=matparams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.random_seed(1)\n",
    "n_draw = 10\n",
    "t_stim = np.linspace(0, test_data[\"duration\"], test_data[\"stim\"].shape[1])\n",
    "plt.subplot(311).imshow(test_data[\"stim\"], extent=(0, test_data[\"duration\"], f_min, f_max))\n",
    "vax = plt.subplot(312)\n",
    "ax = plt.subplot(313)\n",
    "for j, spk in enumerate(test_data[\"spike_t\"]):\n",
    "    ax.vlines(spk * model_dt, j, j + 0.5, 'r')\n",
    "    \n",
    "samples = np.random.permutation(nwalkers)[:n_draw]\n",
    "pred = np.zeros((test_data[\"spike_v\"].shape[0], n_draw), dtype=test_data[\"spike_v\"].dtype)\n",
    "for i, idx in enumerate(samples):\n",
    "    mparams = pos[idx]\n",
    "    V_mc = mltest.V(mparams)\n",
    "    vax.plot(t_stim, V_mc)\n",
    "    pred[:, i] = mltest.predict(mparams, matparams[3:], V_mc)\n",
    "    spk_t = pred[:, i].nonzero()[0]\n",
    "    ax.vlines(spk_t * model_dt, i + j + 1, i + j + 1.5)\n",
    "pred_psth = spikes.psth(pred, upsample, 1)\n",
    "test_psth = spikes.psth(test_data[\"spike_v\"], upsample, 1)\n",
    "ax.plot(t_stim, test_psth, t_stim, pred_psth)\n",
    "for ax in plt.gcf().axes:\n",
    "    ax.set_xlim(0, 4200)\n",
    "\n",
    "eo = performance.corrcoef(test_data[\"spike_v\"][::2], test_data[\"spike_v\"][1::2], upsample, 1)\n",
    "print(\"loglike: {}\".format(-mltest.loglike(w1)))\n",
    "print(\"CC: {}/{}\".format(np.corrcoef(test_psth, pred_psth)[0, 1], eo))\n",
    "print(\"spike count: data = {}, pred = {}\".format(test_data[\"spike_v\"].sum() / n_trials, pred.sum() / n_draw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for testing in the Pillow code\n",
    "import scipy.io as sio\n",
    "V = mlest.V_interp(theta_true).squeeze()\n",
    "H = assim_resp[0][\"H\"]\n",
    "mu = V - H[:, 0] * matparams[1] - H[:, 1] * matparams[2] - matparams[0]\n",
    "sio.savemat('glmat_2dbi_song_twin.mat', {\"stim\": (stim - stim.mean(1)[:, np.newaxis]) / stim.std(1)[:, np.newaxis], \n",
    "                                         \"spikes\": assim_resp[0][\"spike_v\"],\n",
    "                                         \"stim_dt\": stim_dt,\n",
    "                                         \"spike_dt\": model_dt,\n",
    "                                         \"rf\": k1,\n",
    "                                         \"Istim\": V,\n",
    "                                         \"Itot\": mu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
