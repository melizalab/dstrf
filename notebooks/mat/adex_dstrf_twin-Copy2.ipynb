{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adexdSTRF twin experiment\n",
    "\n",
    "This script runs a twin experiment with a dSTRF model composed of the augmented adexmodel and a cosine basis STRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import neurofit as nf\n",
    "import pyspike as pyspk\n",
    "from scipy.signal import resample\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # for importing utils and glm\n",
    "\n",
    "import utils\n",
    "from models import cosstrf, adex, adex_zero_centered, dstrf_adex\n",
    "\n",
    "from neurofit import utils as nfutils\n",
    "\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import * # plotting functions\n",
    "import seaborn as sns           # data visualization package\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "rcParams[\"svg.fonttype\"]='none'\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Arial']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paramters and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assimilation parameters\n",
    "nwalkers = 1000\n",
    "burn = 1000\n",
    "threads = 8\n",
    "keep = 1\n",
    "num_assim_stims = 15\n",
    "tracker = nfutils.convergence_tracker(burn,burn/10)\n",
    "\n",
    "# dstrf model settings\n",
    "free_ts = False\n",
    "scale = 5\n",
    "channels = 1\n",
    "ncos = 10\n",
    "coslin = 1\n",
    "norm = True\n",
    "center = True\n",
    "\n",
    "# data parameters \n",
    "nspec = 30\n",
    "t_dsample = 5\n",
    "tlen = int(np.rint(150/t_dsample))\n",
    "psth_smooth = 5/t_dsample\n",
    "compress = 1\n",
    "\n",
    "# load data from crcns\n",
    "cell = \"yg0616_4_B\"\n",
    "stim_type = \"conspecific\"\n",
    "\n",
    "stims,durations = utils.load_crcns(cell,stim_type,nspec,t_dsample,compress)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating data for the twin experiment\n",
    "\n",
    "### Building the STRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = np.load('../filters.npz')\n",
    "k = resample(resample(filts['nbs'],nspec,axis=0),tlen,axis=1)\n",
    "#k = nfutils.normalize(k,center=False)\n",
    "\n",
    "figure()\n",
    "sns.heatmap(k,linewidths = 0)\n",
    "\n",
    "figure()\n",
    "B = np.sum(k,axis=1)\n",
    "A = np.sum(k,axis=0)\n",
    "subplot(211)\n",
    "plot(A)\n",
    "subplot(212)\n",
    "plot(B)\n",
    "\n",
    "# create cosine basis for time dimension\n",
    "spec,tim = utils.factorize(k)\n",
    "tbas, fromt, tot = utils.cosbasis(tlen,ncos,coslin,retfn=True)\n",
    "costim = tot(tim)\n",
    " \n",
    "# set adexmodel parameters\n",
    "matparam  = [10,2,0,8]\n",
    "#matparam  = [20,2,0,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set adexmodel parameters\n",
    "matlabs = ['gl','delt','vt','tw','a','vr','b','h']\n",
    "adexparam  = [0.5, 1.0, 10, 50, 1, -10, 10]\n",
    "\n",
    "dataparam = np.hstack((spec[0],costim[0],adexparam))\n",
    "M = dstrf_adex(1,nspec,tlen,ncos,coslin,t_dsample,scale=scale,normalize=norm,center=center)\n",
    "M.set(dataparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EO: 0.83\n"
     ]
    }
   ],
   "source": [
    "# data settings\n",
    "ntrials = 5\n",
    "noise = 0.25\n",
    "dataparam = np.hstack((spec[0],costim[0],adexparam))\n",
    "M = dstrf_adex(1,nspec,tlen,ncos,coslin,t_dsample,scale=scale,noise=noise,normalize=norm,center=center)\n",
    "M.set(dataparam)\n",
    "\n",
    "# generate the data\n",
    "spikes_data = []\n",
    "spiky_data = []\n",
    "binary_data = []\n",
    "model_data   = []\n",
    "for s,dur in zip(stims,durations):\n",
    "    dsdur = int(dur/t_dsample)\n",
    "    sr = []\n",
    "    sspk = []\n",
    "    s0 = []\n",
    "    sspiky = []\n",
    "    for n in range(ntrials):\n",
    "        z = np.zeros(dur,dtype=int)\n",
    "        r,spikes = M.run(s)\n",
    "        z[spikes] = 1\n",
    "        sr.append(r)\n",
    "        sspk.append(spikes)\n",
    "        sspiky.append(pyspk.SpikeTrain(spikes,[0,dur]))\n",
    "        s0.append(z)\n",
    "    model_data.append(sr)\n",
    "    spikes_data.append(sspk)\n",
    "    spiky_data.append(sspiky)\n",
    "    binary_data.append(s0)\n",
    "psth_data = [utils.psth_spiky(spk,smooth=psth_smooth,dsample=t_dsample) for spk,st in zip(spiky_data,stims)]\n",
    "\n",
    "# separate the simulation and validation sets\n",
    "assim_psth, test_psth = np.split(psth_data,[num_assim_stims])\n",
    "assim_spikes, test_spikes = np.split(spikes_data,[num_assim_stims])\n",
    "assim_spiky, test_spiky = np.split(spiky_data,[num_assim_stims])\n",
    "assim_stims, test_stims = stims[:num_assim_stims], stims[num_assim_stims:]\n",
    "assim_dur, test_dur = np.split(durations,[num_assim_stims])\n",
    "\n",
    "# calculate correlation between even and odd trial psths\n",
    "eocorr = [utils.evenoddcorr(spks,dur,dsample=t_dsample,smooth=t_dsample) for spks,dur in zip(spikes_data,durations)]\n",
    "print(\"EO: {:.2f}\".format(np.mean(eocorr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting initial guess for STRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate STRF using elastic net regression\n",
    "fit_psth = [p*1000 for p in assim_psth]\n",
    "#fit_psth = [np.log(p*1000 + 1) for p in assim_psth]\n",
    "\n",
    "STRF_GUESS, B_GUESS = utils.get_strf(assim_stims,fit_psth,tlen,fit_intercept=False)\n",
    "SPEC,TIM = utils.factorize(STRF_GUESS,1)\n",
    "\n",
    "# create initial paramter vector from estimated strf\n",
    "filt_start = np.hstack((SPEC,tot(TIM))).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true and estimated strf\n",
    "subplot(211)\n",
    "sns.heatmap(M.pstrf.filt)\n",
    "\n",
    "subplot(212)\n",
    "strf_model = cosstrf(channels,nspec,tlen,ncos,coslin,normalize=norm,center=center)\n",
    "strf_model.set(filt_start)\n",
    "sns.heatmap(strf_model.filt)\n",
    "\n",
    "print(utils.evaluate(strf_model.filt,test_stims,test_psth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss and prior functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neurofit import priors\n",
    "from neurofit import costs\n",
    "\n",
    "def spike_distance(predict,data):\n",
    "    trace, spikes = predict\n",
    "    spiky = pyspk.SpikeTrain(spikes,[0,data[0].t_end])\n",
    "    dist = 1000*np.mean([pyspk.spike_distance(spiky,trial) for trial in data])\n",
    "    return dist\n",
    "\n",
    "\n",
    "adex_prior = priors.joint_independent(\n",
    "              [priors.uniform(   0,  1),\n",
    "                priors.uniform( 0.5,  2),\n",
    "                priors.uniform(  0,   30),\n",
    "                priors.uniform(   1, 200),\n",
    "                priors.uniform( -10,  10),\n",
    "                priors.uniform( -30,  30),\n",
    "                priors.uniform(   0,  50)])\n",
    "\n",
    "cost = spike_distance\n",
    "unbounded = priors.unbounded()\n",
    "\n",
    "def dstrf_shrink_prior(theta):\n",
    "    return -np.sum(np.abs(theta[:-7])) + adex_prior(theta[-7:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run initial adexparameter fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance of the fit adexmodel\n",
    "mml = adex_smplr.flatchain[np.argmax(adex_smplr.flatlnprobability)]\n",
    "mml = adexparam\n",
    "adex_map = adex_zero_centered()\n",
    "adex_map.set(mml)\n",
    "adex_corr = []\n",
    "\n",
    "param_corr = utils.evaluate(STRF_GUESS,test_stims,test_psth)\n",
    "\n",
    "for i,p,d in zip(test_Iapp,test_psth,test_dur):\n",
    "    trace,spikes = adex_map.run(i)\n",
    "    adex_psth = utils.psth_spiky(pyspk.SpikeTrain(spikes,[0,d]),binres=1,smooth=psth_smooth,dsample=t_dsample)\n",
    "    adex_corr.append(np.corrcoef(p,adex_psth)[0][1])\n",
    "        \n",
    "start = np.hstack((filt_start,mml))\n",
    "print(\"Filt R: {:.3f}, adexR: {:.3f}\".format(param_corr,np.mean(adex_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit dSTRF model using emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the model\n",
    "model = dstrf_adex(channels,nspec,tlen,ncos,coslin,t_dsample,scale=scale,normalize=norm,center=center)\n",
    "\n",
    "p0 = startpos.normal_independent(nwalkers-1,start,[1e-4]*len(start))\n",
    "p0 = np.vstack((start,p0))\n",
    "\n",
    "\n",
    "# run emcee\n",
    "dstrf_smplr = nf.sampler(model,dstrf_shrink_prior,spike_distance,nwalkers,zip(assim_stims,assim_spiky),threads)\n",
    "for pos,_,_ in tracker(dstrf_smplr.sample(p0,iterations=burn)): continue\n",
    "dstrf_smplr.reset()\n",
    "dstrf_smplr.run_mcmc(pos,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize model with MAP parameter estimate\n",
    "dmap = dstrf_smplr.flatchain[np.argmax(dstrf_smplr.flatlnprobability)]\n",
    "model.set(dmap)\n",
    "\n",
    "figure(figsize=(4,4))\n",
    "# compare true and estimated STRFs\n",
    "subplot(211)\n",
    "sns.heatmap(M.pstrf.filt,)\n",
    "\n",
    "subplot(212)\n",
    "sns.heatmap(model.pstrf.filt)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figroot = \"/scratch/dstrf/figures/adex_twin/\"\n",
    "\n",
    "\n",
    "rcParams[\"svg.fonttype\"]='none'\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Arial']})\n",
    "\n",
    "ch = sns.color_palette(\"cubehelix\",8).as_hex()\n",
    "ch4 = sns.color_palette(\"cubehelix\",4).as_hex()\n",
    "\n",
    "rcParams[\"svg.fonttype\"]='none'\n",
    "rc('font',**{'family':'serif','serif':['Times']})\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Arial']})\n",
    "\n",
    "ch4[3] = u'#97a6ed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAP: 0.84, Dist: 0.88, EO: 0.78\n",
      "MAP/EO: 1.07, Dist/EO: 1.12\n"
     ]
    }
   ],
   "source": [
    "map_corr,mapsths = utils.dstrf_sample_validate(model,dmap,test_stims,test_psth,t_dsample,psth_smooth)\n",
    "ppcorr, ppsths = utils.posterior_predict_corr(model,test_stims,test_psth,dstrf_smplr.flatchain,t_dsample,psth_smooth,ntrials=100)\n",
    "corr_means = np.mean([map_corr,ppcorr,eocorr[num_assim_stims:]],axis=1)\n",
    "\n",
    "print(\"\\nMAP: {:.2f}, Dist: {:.2f}, EO: {:.2f}\".format(corr_means[0],corr_means[1],corr_means[2]))\n",
    "print(\"MAP/EO: {:.2f}, Dist/EO: {:.2f}\".format(corr_means[0]/corr_means[2],corr_means[1]/corr_means[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4,6))\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "chain = dstrf_smplr.flatchain\n",
    "\n",
    "subplot(311)\n",
    "title(\"Spectral\")\n",
    "x = np.arange(0,nspec)\n",
    "plot(nfutils.normalize(chain[:,:-17].T)/6,color=ch4[3],alpha=0.005)\n",
    "plot(nfutils.normalize(model.pstrf.sfilt.T)/6,ch4[3],label=\"estimates\")\n",
    "plot(nfutils.normalize(M.pstrf.sfilt.T)/6,ch4[0],label=\"true filter\")\n",
    "legend()\n",
    "\n",
    "\n",
    "#yticks([])\n",
    "title(\"Spectral\")\n",
    "xticks(range(-1,30,15),range(0,8100,int(8000/2)),rotation=45);\n",
    "yticks([])\n",
    "xlabel(\"Hz\")\n",
    "\n",
    "subplot(312)\n",
    "title(\"Temporal\")\n",
    "x = np.arange(0,nspec)\n",
    "plot(nfutils.normalize(fromt(chain[:,nspec:-7]).T)/4,color=ch4[3],alpha=0.005)\n",
    "plot(nfutils.normalize(M.pstrf.tfilt.T)/4,ch4[0],label=\"true filter\")\n",
    "yticks([])\n",
    "xticks([0,10,20,30],[0,50,100,150])\n",
    "xlabel(\"ms\")\n",
    "\n",
    "\n",
    "sns.despine(offset=5,trim=True,left=True)\n",
    "tight_layout()\n",
    "\n",
    "savefig(figroot+\"marg.svg\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [   ],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "\n",
    "figure(figsize=(4,6))\n",
    "model.set(np.mean(chain,0))\n",
    "\n",
    "from neurofit import graphics\n",
    "\n",
    "#figure()\n",
    "subplot(211)\n",
    "title(\"True Filter\")\n",
    "#graphics.strf_plot(M.k.sfilt,M.k.tfilt,0,8000,t_dsample)\n",
    "sns.heatmap(M.pstrf.filt,cbar=False)\n",
    "\n",
    "yticks(range(-1,30,15),range(0,8100,int(8000/2)),rotation=45);\n",
    "xticks([0,10,20,30],[0,50,100,150])\n",
    "ylabel(\"Hz\")\n",
    "\n",
    "\n",
    "subplot(212)\n",
    "title(\"Estimated Filter\")\n",
    "sns.heatmap(model.pstrf.filt,cbar=False)\n",
    "yticks(range(-1,30,15),range(0,8100,int(8000/2)),rotation=90);\n",
    "xticks([0,10,20,30],[0,50,100,150])\n",
    "xlabel(\"ms\")\n",
    "ylabel(\"Hz\")\n",
    "\n",
    "sns.despine(trim=True, offset=5)\n",
    "tight_layout()\n",
    "\n",
    "subplot(211)\n",
    "yticks(range(-1,30,15),range(0,8100,int(8000/2)),rotation=90);\n",
    "subplot(212)\n",
    "yticks(range(-1,30,15),range(0,8100,int(8000/2)),rotation=90);\n",
    "\n",
    "\n",
    "#graphics.strf_plot(model.k.sfilt,model.k.tfilt,0,8000,t_dsample)\n",
    "\n",
    "savefig(figroot+\"strf.svg\",bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
